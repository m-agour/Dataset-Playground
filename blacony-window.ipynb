{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"raw","source":"### !pip install shapely==2.0.1 -q","metadata":{"execution":{"iopub.status.busy":"2023-09-11T22:42:50.521601Z","iopub.execute_input":"2023-09-11T22:42:50.521994Z","iopub.status.idle":"2023-09-11T22:42:50.530019Z","shell.execute_reply.started":"2023-09-11T22:42:50.521958Z","shell.execute_reply":"2023-09-11T22:42:50.526022Z"}}},{"cell_type":"code","source":"!pip install shapely==2.0.1 -q\n!pip install segmentation_models_pytorch -q","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:18:50.750304Z","iopub.execute_input":"2023-09-13T01:18:50.750947Z","iopub.status.idle":"2023-09-13T01:19:22.893673Z","shell.execute_reply.started":"2023-09-13T01:18:50.750906Z","shell.execute_reply":"2023-09-13T01:19:22.892349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import bz2\nimport lzma\nimport pickle\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport shapely\nimport tqdm\nfrom shapely.geometry import box\nfrom shapely.geometry import MultiPolygon, Point, GeometryCollection, MultiLineString\nfrom shapely import affinity\nfrom uuid import uuid4\nimport geopandas as gpd\nimport bz2\nimport lzma\nimport pickle\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport shapely\nimport tqdm\nfrom shapely.geometry import box\nfrom shapely.geometry import MultiPolygon, Point, GeometryCollection, MultiLineString\nfrom shapely import affinity\nfrom uuid import uuid4\nfrom typing import Iterable\nimport random\nimport cv2, pickle\nimport numpy as np\nimport shapely\nfrom pandas import Series\nfrom shapely import MultiPolygon, Polygon, box, Point\nfrom shapely.affinity import scale\nimport gc, torch\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:19:22.897106Z","iopub.execute_input":"2023-09-13T01:19:22.898430Z","iopub.status.idle":"2023-09-13T01:19:25.913499Z","shell.execute_reply.started":"2023-09-13T01:19:22.898377Z","shell.execute_reply":"2023-09-13T01:19:25.912396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c = 0\nsize = 256\n\ndef buffer(p, w, bm=0.5):\n    p = affinity.scale(p, xfact=0.9, yfact=0.9, origin=(size / 2, size / 2)) if p else Point(-100, -100)\n    if bm:\n        if isinstance(p, shapely.geometry.multipolygon.MultiPolygon):\n            return [i.buffer(-bm * w, join_style=2).buffer((1.5 + bm) * w, join_style=2).buffer(-1.5 * w, join_style=2)\n                    for i in p.geoms]\n        return [p.buffer(-bm * w, join_style=2).buffer((1.5 + bm) * w, join_style=2).buffer(-1.5 * w, join_style=2)]\n    return p\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:19:25.915221Z","iopub.execute_input":"2023-09-13T01:19:25.916095Z","iopub.status.idle":"2023-09-13T01:19:25.926380Z","shell.execute_reply.started":"2023-09-13T01:19:25.916053Z","shell.execute_reply":"2023-09-13T01:19:25.925064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plans = pickle.load(open('/kaggle/input/with-kit/Planify_ocr_kit.pkl', 'rb'))\nold_plans = pickle.load(open('/kaggle/input/planify-cleaned-neigh/Planify_cleaned_neigh.pkl', 'rb'))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-13T01:19:25.929555Z","iopub.execute_input":"2023-09-13T01:19:25.930636Z","iopub.status.idle":"2023-09-13T01:19:36.476488Z","shell.execute_reply.started":"2023-09-13T01:19:25.930594Z","shell.execute_reply":"2023-09-13T01:19:36.465699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, plan in enumerate(plans):\n    old_plan = old_plans[i]\n    plan[\"neigh\"] = old_plan[\"neigh\"]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:19:36.477949Z","iopub.execute_input":"2023-09-13T01:19:36.478355Z","iopub.status.idle":"2023-09-13T01:19:36.506107Z","shell.execute_reply.started":"2023-09-13T01:19:36.478316Z","shell.execute_reply":"2023-09-13T01:19:36.505046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_plan_width(plan):\n    inner = plan[\"inner\"]\n    x1, y1, x2, y2 = inner.bounds\n    w, h = x2-x1, y2-y1\n    diameter = max(w, h)\n    return diameter\n\nplans = [i for i in plans if get_plan_width(i) <= 260]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:19:36.508061Z","iopub.execute_input":"2023-09-13T01:19:36.509108Z","iopub.status.idle":"2023-09-13T01:19:36.746684Z","shell.execute_reply.started":"2023-09-13T01:19:36.509067Z","shell.execute_reply":"2023-09-13T01:19:36.745500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aug_prefs = [\n    [0, False],\n    [0, True],\n    [90, False],\n    [90, True],\n    [180, False],\n    [180, True],\n    [270, False],\n    [270, True]\n]\n\ndef augment(polygon, degree, flip_vertical, scale=1, size=256, point=False):\n    if not polygon:\n        return Point(-100, -100) if point else box(-100, -100, -100, -100)\n    p = affinity.rotate(polygon, degree, origin=(size / 2, size / 2))\n    flip = 1\n    if flip_vertical:\n        flip = -1\n    p = affinity.scale(p, xfact=scale, yfact=scale * flip, origin=(size / 2, size / 2))\n    return p","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:19:36.748701Z","iopub.execute_input":"2023-09-13T01:19:36.749245Z","iopub.status.idle":"2023-09-13T01:19:36.761074Z","shell.execute_reply.started":"2023-09-13T01:19:36.749198Z","shell.execute_reply":"2023-09-13T01:19:36.759960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef get_mask(poly, shape=(256, 256), point_s=5, line_s=0):\n    \"\"\" Return image contains multiploygon as a numpy array mask\n\n    Parameters\n    ----------\n    poly: Polygon or MultiPolygon or Iterable[Polygon or MultiPolygon]\n        The Polygon/s to get mask for\n    shape: tuple\n        The shape of the canvas to draw polygon/s on\n\n    Returns\n    -------\n    ndarray\n        Mask array of the input polygon/s\n        :param point_s:\n\n    \"\"\"\n\n    img = np.zeros(shape, dtype=np.uint8)\n    if isinstance(poly, Polygon):\n        if poly.is_empty:\n            return img\n        if line_s:\n            points = np.array(poly.exterior.coords[:], dtype=np.int32)\n            img = cv2.polylines(img, [points], True, 255, thickness=line_s)\n        else:\n            img = cv2.drawContours(img, np.int32([poly.exterior.coords]), -1, 255, -1)\n\n        for interior in poly.interiors:\n\n            points = np.array(interior.coords[:], dtype=np.int32)\n            if line_s:\n                img = cv2.polylines(img, [points], True, 0, thickness=line_s)\n            else:\n                img = cv2.drawContours(img, np.int32([interior.coords]), -1, 0, -1)\n\n    elif isinstance(poly, MultiPolygon):\n        for p in poly.geoms:\n            if line_s:\n                points = np.array(p.exterior.coords[:], dtype=np.int32)\n                img = cv2.polylines(img, [points], True, 255, thickness=line_s)\n            else:\n                img = cv2.drawContours(img, np.int32([p.exterior.coords]), -1, 255, -1)\n\n    elif isinstance(poly, Series):\n        polys = [p for p in poly.tolist() if p]\n        img = get_mask(polys, shape, point_s, line_s)\n\n    elif isinstance(poly, Iterable):\n        for p in poly:\n            img = (img != 0) | (get_mask(p, shape, point_s, line_s) != 0)\n        img = img.astype(np.uint8) * 255\n    elif isinstance(poly, Point):\n        p = poly.coords[0]\n        img = cv2.circle(img, (int(p[0]), int(p[1])), point_s, 255, -1)\n    return img.astype(np.uint8)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:19:36.763356Z","iopub.execute_input":"2023-09-13T01:19:36.764142Z","iopub.status.idle":"2023-09-13T01:19:36.784609Z","shell.execute_reply.started":"2023-09-13T01:19:36.764101Z","shell.execute_reply":"2023-09-13T01:19:36.783451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_centroid(poly):\n    x1, x2, y1, y2 = 0, 0, 0, 0","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:19:36.786637Z","iopub.execute_input":"2023-09-13T01:19:36.787239Z","iopub.status.idle":"2023-09-13T01:19:36.800730Z","shell.execute_reply.started":"2023-09-13T01:19:36.787199Z","shell.execute_reply":"2023-09-13T01:19:36.799571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nMIN_ROOM_AREA = 8.5\nMAX_ROOM_AREA = 46\nMIN_BROOM_AREA = 3.5\nMAX_BROOM_AREA = 15\n\ndef rand_room_area(n):\n    total = 0\n    for i in range(n):\n        MIDPOINT = (MIN_ROOM_AREA + MAX_ROOM_AREA) / 2\n        STD_DEV = (MAX_ROOM_AREA - MIN_ROOM_AREA) / 4\n        room_area = random.normalvariate(MIDPOINT, STD_DEV)\n        room_area = max(min(room_area, MAX_ROOM_AREA), MIN_ROOM_AREA)\n        room_area = round(room_area, 2)\n        total += room_area\n    return total\n\ndef rand_broom_area(n):\n    total = 0\n    for i in range(n):\n        MIDPOINT = (MIN_BROOM_AREA + MAX_BROOM_AREA) / 2\n        STD_DEV = (MAX_BROOM_AREA - MIN_BROOM_AREA) / 4\n        room_area = random.normalvariate(MIDPOINT, STD_DEV)\n        room_area = max(min(room_area, MAX_BROOM_AREA), MIN_BROOM_AREA)\n        room_area = round(room_area, 2)\n        total += room_area\n    return total\n\ndef estimate_total_area(num_bedrooms, num_bathrooms):\n    avg_ratio_1br_1ba = 0.6\n    avg_ratio_2br_2ba = 0.7\n    avg_ratio_3br_nba = 0.75\n    combined_bed_bath_area = rand_room_area(num_bedrooms) + rand_broom_area(num_bathrooms)\n    if num_bedrooms == 1 and num_bathrooms == 1:\n        area_ratio = avg_ratio_1br_1ba\n    elif num_bedrooms == 2 and num_bathrooms == 2:\n        area_ratio = avg_ratio_2br_2ba\n    else:\n        area_ratio = avg_ratio_3br_nba\n    total_area = combined_bed_bath_area / area_ratio\n\n    return total_area\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:19:36.806344Z","iopub.execute_input":"2023-09-13T01:19:36.806645Z","iopub.status.idle":"2023-09-13T01:19:36.821437Z","shell.execute_reply.started":"2023-09-13T01:19:36.806616Z","shell.execute_reply":"2023-09-13T01:19:36.820218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc, torch\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:19:36.823181Z","iopub.execute_input":"2023-09-13T01:19:36.824208Z","iopub.status.idle":"2023-09-13T01:19:37.133053Z","shell.execute_reply.started":"2023-09-13T01:19:36.824143Z","shell.execute_reply":"2023-09-13T01:19:37.131558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def perturb_polygon(polygon, x_range=(-2, 2), y_range=(-2, 2)):\n    \"\"\"\n    Apply random perturbation to the coordinates of a shapely polygon.\n\n    Args:\n        polygon (Polygon): The original shapely polygon.\n        x_range (tuple): The range for random perturbation in x-axis. Default is (-0.1, 0.1).\n        y_range (tuple): The range for random perturbation in y-axis. Default is (-0.1, 0.1).\n\n    Returns:\n        Polygon: The perturbed shapely polygon.\n    \"\"\"\n    # Get the coordinates of the original polygon\n    original_coords = np.array(polygon.exterior.coords)\n\n    # Iterate through each vertex of the original polygon\n    perturbed_coords = []\n    for x, y in original_coords:\n        # Generate a random perturbation for x and y coordinates within the specified range\n        perturbation_x = np.random.uniform(x_range[0], x_range[1])\n        perturbation_y = np.random.uniform(y_range[0], y_range[1])\n\n        # Apply the perturbation to the original coordinates\n        perturbed_x = x + perturbation_x\n        perturbed_y = y + perturbation_y\n\n        perturbed_coords.append((perturbed_x, perturbed_y))\n\n    # Create a new Polygon object with the perturbed coordinates\n    perturbed_polygon = Polygon(perturbed_coords)\n\n    return perturbed_polygon\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:19:37.134837Z","iopub.execute_input":"2023-09-13T01:19:37.135549Z","iopub.status.idle":"2023-09-13T01:19:37.146435Z","shell.execute_reply.started":"2023-09-13T01:19:37.135510Z","shell.execute_reply":"2023-09-13T01:19:37.145216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef noise(point, noise_scale=10):\n    # Add random noise to the point\n    x, y = point.coords[0]\n    dx_noise = random.uniform(-noise_scale, noise_scale)\n    dy_noise = random.uniform(-noise_scale, noise_scale)\n    noisy_point = Point(x + dx_noise, y + dy_noise)\n\n\n    return noisy_point","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:19:37.149826Z","iopub.execute_input":"2023-09-13T01:19:37.150682Z","iopub.status.idle":"2023-09-13T01:19:37.164800Z","shell.execute_reply.started":"2023-09-13T01:19:37.150638Z","shell.execute_reply":"2023-09-13T01:19:37.163580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plan = plans[10]\n# inner = perturb_polygon(plan['inner'].geoms[0]).buffer(0)\n# front = plan['front'].buffer(4).intersection(inner.exterior).centroid\n# gpd.GeoSeries([front, inner]).plot(cmap='Dark2_r')\n# print(front,  plan['front'])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:19:37.166817Z","iopub.execute_input":"2023-09-13T01:19:37.167803Z","iopub.status.idle":"2023-09-13T01:19:37.175015Z","shell.execute_reply.started":"2023-09-13T01:19:37.167744Z","shell.execute_reply":"2023-09-13T01:19:37.173969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len([i for i in plans if len(i['bathroom'].geoms) == 4 ])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:19:37.177933Z","iopub.execute_input":"2023-09-13T01:19:37.179590Z","iopub.status.idle":"2023-09-13T01:19:37.441342Z","shell.execute_reply.started":"2023-09-13T01:19:37.179547Z","shell.execute_reply":"2023-09-13T01:19:37.440186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport keras, os, random\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn\n\nonehot = {}\nfor i in [1, 2, 3, 4]:\n    for j in [1, 2, 3, 4]:\n        img = np.zeros((256, 256, 8))\n        img[:, :, i-1] =  np.ones((256, 256))\n        img[:, :, j+4-1] = 1\n        onehot[(i, j)] = img[:, :, :]\n\nimport torch\nimport numpy as np\nfrom torch.utils.data import Dataset\n\nimport torch\nfrom torch.utils.data import Dataset\n\ndef centroid(poly):\n    x1, y1, x2, y2 = poly.bounds\n    return Point((x2+x1)/2, (y2+y1)/2)\n\nclass PlanDataset(Dataset):\n    def __init__(self, plans, batch_size=32, image_size=(256, 256), aug_p=None):\n        self.plans = plans\n        self.batch_size = batch_size\n        self.image_size = image_size\n        self.num_samples = len(self.plans)\n        self.aug_p = aug_p\n\n    def __len__(self):\n        return self.num_samples\n\n    def __getitem__(self, idx):\n        plan = self.plans[idx]\n        deg, flip = random.choice(aug_prefs)\n        deg = deg + random.randint(-3, 3)\n        \n        if self.aug_p:\n            deg, flip = self.aug_p\n#         deg = deg + random.randint(-5, 5)\n        no_bedrooms = min(max(1, len(plan['bedroom'].geoms)), 3)\n        \n        no_bathrooms = min(max(1, len(plan['bathroom'].geoms)), 3)\n        \n#         area = estimate_total_area(no_bedrooms, no_bathrooms)\n\n#         case = random.choice([f for f in range(1, no_bedrooms+1) for j in range(f)]) if no_bedrooms > 1 else 1\n#         inbedsnum = case-1\n\n        x = np.zeros((*self.image_size, 2))\n        x1 = np.zeros((*self.image_size, 3))\n        y = np.zeros((*self.image_size, 1))\n        \n#         deg = random.randint(0, 360)\n\n#         x[:,:,:8] = onehot[(no_bedrooms, no_bathrooms)][:,:,:8]\n#         x[:,:,9] = get_mask(augment(plan['front'], deg, flip), (256, 256), point_s=7) > 0\n#         x[:,:,10] = get_mask(augment(plan['inner_g'], deg, flip), (256, 256), point_s=10) > 0\n#         x[:,:,11 + inbedsnum] = 1\n        s = 0.8\n        inner = perturb_polygon(plan['inner'].geoms[0] , x_range=(-0, 0), y_range=(-0, 0)).buffer(0)\n#         inner = plan['inner'].buffer(0)\n    \n        noif = 2\n\n        inner = inner if isinstance(inner, Polygon) else max(inner.geoms, key=lambda x:x.area)\n        front = plan['front'].buffer(8).intersection(inner.exterior).centroid\n        if not front:\n            front = plan['front']\n        front = augment(front, deg, flip, s)\n        \n#         bedrooms = sorted([augment(f, deg, flip, s) for f in plan['bedroom'] if inner.contains(f)], key=lambda pp:pp.area, reverse=True)\n#         bathrooms = sorted([augment(f, deg, flip, s) for f in plan['bathroom'] if inner.contains(f)], key=lambda pp:pp.area, reverse=True)\n#         inner_ext = augment(inner, deg, flip, s).exterior.buffer(10)\n#         bedrooms = sorted([augment(f, deg, flip, s) for f in plan['bedroom'] if inner.contains(f)], key=lambda pp:pp.exterior.buffer(5).intersection(inner_ext).area, reverse=True)\n#         bathrooms = sorted([augment(f, deg, flip, s) for f in plan['bathroom'] if inner.contains(f)], key=lambda pp:pp.exterior.buffer(5).intersection(inner_ext).area, reverse=True)\n\n        try:\n            bedrooms = sorted([augment(f, deg, flip, s) for f in plan['bedroom'].geoms], key=lambda pp:pp.centroid.distance(front), reverse=True)\n            bathrooms = sorted([augment(f, deg, flip, s) for f in plan['bathroom'].geoms], key=lambda pp:pp.centroid.distance(front), reverse=True)\n        except:\n            print(front, [augment(f, deg, flip, s) for f in plan['bedroom'].geoms], [augment(f, deg, flip, s) for f in plan['bathroom'].geoms])\n#         bedroomscn = [noise(f.centroid, noif) for f in bedrooms]\n#         bathroomscn = [noise(f.centroid, noif) for f in bathrooms]\n        bedroomsc = [f.centroid for f in bedrooms]\n        bathroomsc = [f.centroid for f in bathrooms]\n        x[:,:,0] = get_mask(front, (256, 256), point_s=7) > 0\n        x[:,:,1] = get_mask(augment(inner, deg, flip, s), (256, 256), point_s=10) > 0\n#         x[:,:,2] = get_mask(bedroomsc, (256, 256), point_s=5) > 0\n#         x[:,:,3] = get_mask(bathroomsc, (256, 256), point_s=5) >0\n#         x[:,:,2:] = get_mask(bedroomsc, (256, 256), point_s=5) > 0\n#         bedrooms = [f.buffer(0, join_style=2, cap_style=2) for f in bedrooms]\n#         bathrooms = [f.buffer(0, join_style=2, cap_style=2) for f in bathrooms]\n#         x[:,:,2] = min(1, area / 500)\n\n\n#         x[:,:,2:10] = onehot[(no_bedrooms, no_bathrooms)]\n\n\n#         random.shuffle(bedroomsc)\n        \n        \n#         x[:,:,10] = get_mask([noise(bp, noif) for bp in bedroomsc], (256, 256), point_s=8) > 0\n#         x[:,:,11] = get_mask([noise(bp, noif) for bp in bathroomsc], (256, 256), point_s=8) > 0\n\n#         kitchen = augment(plan['kitchen'], deg, flip,  s).centroid\n        \n#         x[:,:,3] = get_mask(bedrooms, (256, 256), point_s=5) > 0\n        \n\n#         inbeds = []\n#         for _ in range(inbedsnum):\n#             bedroom = random.choice(bedrooms)\n#             bedc = bedroom.minimum_rotated_rectangle.centroid if bedroom else Point(-100, -100)\n#             bedrooms = [x for x in bedrooms if x != bedroom]\n#             inbeds.append(augment(bedc, deg, flip))\n#         general = MultiPolygon(plan['general']) if isinstance(plan['general'], list) else plan['general']\n#         general = inner if isinstance(general, Polygon) else max(general.geoms, key=lambda x:x.area)\n#         x[:,:,10] = get_mask(bedroomsc[0], (256, 256), point_s=8) > 0\n        y[:,:,0] = get_mask(augment(plan['kitchen'].centroid, deg, flip, s), (256, 256), point_s=8) > 0\n        x1[:,:,0] = get_mask(bedroomsc, (256, 256), point_s=8) > 0\n        x1[:,:,1] = get_mask(bathroomsc, (256, 256), point_s=8) > 0\n#         y[:,:,1] = get_mask(bathroomsc[:1], (256, 256), point_s=6) > 0\n#         y[:,:,2] = get_mask(augment(general, deg, flip, scale=s).centroid, point_s=8) > 0\n\n#         bedroom = random.choice(bedrooms).minimum_rotated_rectangle.centroid if bedrooms else Point(-100, -100)\n#         walls = augment(plan['wall'].buffer(2, join_style=2, cap_style=2), deg, flip, s * 0.9)\n#         doors = augment(plan['door'].buffer(2, join_style=2, cap_style=2), deg, flip, s * 0.9)\n#         windows = augment(plan['window'].buffer(2, join_style=2, cap_style=2), deg, flip, s * 0.9)\n#         y[:,:,0] = (get_mask(walls, (256, 256), point_s=5)/255.0 + get_mask(doors, (256, 256), point_s=5)/255.0 + get_mask(windows, (256, 256), point_s=5)/255.0)>0\n#         y[:,:,1] = (get_mask(walls, (256, 256), point_s=5)/255.0 + get_mask(doors, (256, 256), point_s=5)/255.0 + get_mask(windows, (256, 256), point_s=5)/255.0)>0\n#######################################################################\n#         y[:,:,0] = (get_mask(walls, (256, 256), point_s=5)/255.0 + get_mask(doors, (256, 256), point_s=5)/255.0 + get_mask(windows, (256, 256), point_s=5)/255.0)>0\n#         y[:,:,0] *= 1-y[:,:,2]\n#         y[:,:,1] *= 1-y[:,:,2]\n#######################################################################\n#         y[:,:,1] = get_mask([d.centroid for d in doors.geoms]  if isinstance(doors, MultiPolygon) else doors.centroid, (256, 256), point_s=3) > 0\n#         y[:,:,2] = get_mask([d.centroid for d in windows.geoms] if isinstance(windows, MultiPolygon) else windows.centroid, (256, 256), point_s=3) > 0\n#         all_romes = shapely.ops.unary_union(bedrooms+bathrooms )\n#         buffered = [br.buffer(plan['wall_width'], join_style=2).difference(all_romes) for br in bedrooms + bathrooms ]\n#         y[:,:,0] = get_mask(buffered, (256, 256), point_s=7) > 0\n#         y[:,:,2] = get_mask(kitchen, (256, 256), point_s=7) > 0\n        area = plan['area']\n        area += random.randint(-5, 20)\n        \n        one_hot = torch.zeros((4, 8, 8)).float()\n        one_hot[no_bedrooms-1] = 1.0\n        return torch.from_numpy(x).permute(2, 0, 1).float(), torch.tensor(norm_area(area)).float(), torch.from_numpy(y).permute(2, 0, 1).float(), one_hot.float(), torch.from_numpy(x1).permute(2, 0, 1).float()\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:19:37.443218Z","iopub.execute_input":"2023-09-13T01:19:37.443938Z","iopub.status.idle":"2023-09-13T01:19:45.250831Z","shell.execute_reply.started":"2023-09-13T01:19:37.443898Z","shell.execute_reply":"2023-09-13T01:19:45.249610Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nbedd = {f\"bed{i+1}\":i for i in range(3)}\nnbathd = {f\"bath{i+1-3}\":i for i in range(3, 6)}\nnd = {**nbedd, **nbathd}","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:19:45.252765Z","iopub.execute_input":"2023-09-13T01:19:45.253718Z","iopub.status.idle":"2023-09-13T01:19:45.261932Z","shell.execute_reply.started":"2023-09-13T01:19:45.253671Z","shell.execute_reply":"2023-09-13T01:19:45.260863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_width_height(poly):\n    x1, y1, x2, y2 = poly.bounds\n    return x2-x1, y2-y1","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:19:45.263680Z","iopub.execute_input":"2023-09-13T01:19:45.264171Z","iopub.status.idle":"2023-09-13T01:19:45.272951Z","shell.execute_reply.started":"2023-09-13T01:19:45.264116Z","shell.execute_reply":"2023-09-13T01:19:45.271935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from shapely.ops import unary_union\nimport numpy as np\nimport os, random\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport numpy as np\nfrom torch.utils.data import Dataset\n\nimport torch\nfrom torch.utils.data import Dataset","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:19:45.274598Z","iopub.execute_input":"2023-09-13T01:19:45.275106Z","iopub.status.idle":"2023-09-13T01:19:45.290917Z","shell.execute_reply.started":"2023-09-13T01:19:45.275066Z","shell.execute_reply":"2023-09-13T01:19:45.289873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_centroids(list_rooms):\n    return [centroid(r) for r in list_rooms]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:19:45.292696Z","iopub.execute_input":"2023-09-13T01:19:45.293122Z","iopub.status.idle":"2023-09-13T01:19:45.302166Z","shell.execute_reply.started":"2023-09-13T01:19:45.293083Z","shell.execute_reply":"2023-09-13T01:19:45.301080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"onehot.keys()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:19:45.305326Z","iopub.execute_input":"2023-09-13T01:19:45.306079Z","iopub.status.idle":"2023-09-13T01:19:45.317039Z","shell.execute_reply.started":"2023-09-13T01:19:45.306039Z","shell.execute_reply":"2023-09-13T01:19:45.315790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def norm_area(area):\n    return (area - 30) / 220\n\ndef restore_area(area):\n    return area * 220 + 30\n\n\nonehot = {}\nfor i in [1, 2, 3, 4]:\n    for j in [1, 2, 3, 4]:\n        img = torch.zeros((256, 256, 8))\n        img[:, :, i-1] =  torch.ones((256, 256))\n        img[:, :, j+4-1] = 1\n        onehot[(i, j)] = img[:, :, :]\n\n\n\nclass PlanDataset(Dataset):\n    def __init__(self, plans, batch_size=32, image_size=(256, 256), aug_p=None, state=None, val=False):\n        self.plans = plans\n        self.batch_size = batch_size\n        self.image_size = image_size\n        self.num_samples = len(self.plans)\n        self.aug_p = aug_p\n        self.val=val\n        self.state = state\n        \n    def __len__(self):\n        return self.num_samples\n\n    def __getitem__(self, idx):\n        plan = self.plans[idx]\n        deg, flip = random.choice(aug_prefs)\n#         deg = deg + random.randint(-3, 3)\n        s = 0.8\n        buffer_range = 0\n        \n        area = min(plan['size'] / 400, 1)\n        \n        \n\n        if self.aug_p:\n            deg, flip = self.aug_p\n            \n        perturb_range = 4\n        \n        if not self.val:\n            x1, y1, x2, y2 = plan['inner'].bounds\n            w, h = x2-x1, y2-y1\n            \n            mi, ma = min(w, h), max(w, h)\n            buffer_range = random.randint(0, 30)\n            buffer_range = buffer_range * mi / ma\n#             deg = deg + random.randint(-5, 5)\n#             perturb_range = 3\n            perturb_range = random.randint(0, perturb_range)\n            perturb_range = 0\n            \n        ww = plan[\"wall_width\"]\n        no_bedrooms = min(max(1, len(plan['bedroom'].geoms)), 4)\n        no_bathrooms = min(max(1, len(plan['bathroom'].geoms)), 4)\n        \n        neighbours, non_neighbours = plan[\"neigh\"]\n        \n        neighbours = augment(unary_union(neighbours), deg, flip, s)\n        non_neighbours = augment(unary_union(non_neighbours), deg, flip, s).buffer(ww)\n        \n        \n        \n        x1 = np.zeros((*self.image_size, 12))\n        x2 = np.zeros((*self.image_size, 3))\n        y = np.zeros((*self.image_size, 1))\n        \n        inner = plan['inner'].geoms[0]\n        inner = inner.buffer(buffer_range, join_style=2, cap_style=2).buffer(-buffer_range, join_style=2, cap_style=2)\n        \n#         try:\n#             inner = perturb_polygon( inner, x_range=(-perturb_range, perturb_range), y_range=(-perturb_range, perturb_range)).buffer(0)\n#         except:\n#             ...\n    \n        inner = inner if isinstance(inner, Polygon) else max(inner.geoms, key=lambda x:x.area)\n        front = plan['front_door'].buffer(8).intersection(inner.exterior)\n        random_distance = random.uniform(0, front.length)\n        front = front.interpolate(random_distance)\n        \n        if not front:\n            front = plan['front_door']\n            \n        front = augment(front, deg, flip, s)\n        inner = augment(inner, deg, flip, s)\n\n        bedrooms = [augment(f, deg, flip, s) for f in plan['bedroom'].geoms]\n        bathrooms = [augment(f, deg, flip, s) for f in plan['bathroom'].geoms]\n        kitchen = [augment(f, deg, flip, s) for f in plan['kitchen'].geoms]\n        blacony = [augment(f, deg, flip, s) for f in plan['balacony'].geoms]\n        door = [augment(f, deg, flip, s) for f in plan['door'].geoms]\n        window = [augment(f, deg, flip, s) for f in plan['window'].geoms]\n        \n\n        if self.state is None:\n            state = random.choice([4, 5, 6])\n        else:\n            state = self.state\n        \n#         state = 1\n#         state=4\n\n        x1[:,:,0] = get_mask(front, (256, 256), point_s=5) > 0\n        x1[:,:,1] = get_mask(inner, (256, 256), point_s=5) > 0\n        length_box = 256*area/2\n        x1[:,:,2] = get_mask(box(128-length_box, 128-length_box, 128+length_box, 128+length_box), (256, 256), point_s=10) > 0        \n        x1[:,:,3] = get_mask(neighbours, (256, 256), point_s=5) > 0\n        \n        if state == 1:\n            buf_nei = neighbours.buffer(ww*4)\n            bedrooms = sorted(bedrooms, key=lambda bedr: bedr.intersection(buf_nei).length, reverse=False)\n\n        \n            bedroomsc = [centroid(f) for f in bedrooms]\n            bathroomsc = [centroid(f) for f in bathrooms]\n            kitchenc = [f.centroid for f in kitchen]\n\n            out_idx = random.choice(range(len(bedroomsc)))\n\n            y[:,:,0] = get_mask(bedroomsc[out_idx], (256, 256), point_s=5) > 0\n\n            bedroomsc.pop(out_idx)\n            bedroomsc = bedroomsc[:out_idx]\n\n            if not self.val:\n                bedroomsc = [noise(f, 2) for f in bedroomsc]        \n\n\n            x2[:,:,0] = get_mask(bedroomsc, (256, 256), point_s=5) > 0\n#             x2[:,:,3] = 1.0\n        \n        \n        elif state == 2:\n            un_bed = unary_union(bedrooms).buffer(ww*2)\n            bathrooms = sorted(bathrooms, key=lambda bedr: bedr.intersection(un_bed).length, reverse=False)\n            \n            \n\n            bedroomsc = [centroid(f) for f in bedrooms]\n            bathroomsc = [centroid(f) for f in bathrooms]\n            kitchenc = [f.centroid for f in kitchen]\n        \n            out_idx = random.choice(range(len(bathroomsc)))\n\n            y[:,:,0] = get_mask(bathroomsc[out_idx], (256, 256), point_s=5) > 0\n\n            bathroomsc.pop(out_idx)\n            bathroomsc = bathroomsc[:out_idx]\n\n            if not self.val:\n                bathroomsc = [noise(f, 2) for f in bathroomsc]        \n                bedroomsc = [noise(f, 2) for f in bedroomsc]        \n\n            x2[:,:,0] = get_mask(bedroomsc, (256, 256), point_s=5) > 0\n            x2[:,:,1] = get_mask(bathroomsc, (256, 256), point_s=5) > 0\n#             x2[:,:,4] = 1.0\n\n        elif state == 3:\n    \n            bedroomsc = [centroid(f) for f in bedrooms]\n            bathroomsc = [centroid(f) for f in bathrooms]\n            kitchenc = [f.centroid for f in kitchen]\n            \n            if not self.val:\n                bathroomsc = [noise(f, 2) for f in bathroomsc]        \n                bedroomsc = [noise(f, 2) for f in bedroomsc]   \n            \n            y[:,:,0] = get_mask(kitchenc, (256, 256), point_s=5) > 0\n            x2[:,:,0] = get_mask(bedroomsc, (256, 256), point_s=5) > 0\n            x2[:,:,1] = get_mask(bathroomsc, (256, 256), point_s=5) > 0\n\n        elif state == 4:\n    \n            x2[:,:,0] = get_mask(bedrooms, (256, 256), point_s=5) > 0\n            x2[:,:,1] = get_mask(bathrooms, (256, 256), point_s=5) > 0\n            x2[:,:,2] = get_mask(kitchen, (256, 256), point_s=5) > 0\n            y[:,:,0] = get_mask(get_centroids(blacony), (256, 256), point_s=5) > 0\n            \n        elif state == 5:\n    \n            x2[:,:,0] = get_mask(bedrooms, (256, 256), point_s=5) > 0\n            x2[:,:,1] = get_mask(bathrooms, (256, 256), point_s=5) > 0\n            x2[:,:,2] = get_mask(kitchen, (256, 256), point_s=5) > 0\n            y[:,:,0] = get_mask(get_centroids(door), (256, 256), point_s=5) > 0\n            \n        elif state == 6:\n    \n            x2[:,:,0] = get_mask(bedrooms, (256, 256), point_s=5) > 0\n            x2[:,:,1] = get_mask(bathrooms, (256, 256), point_s=5) > 0\n            x2[:,:,2] = get_mask(kitchen, (256, 256), point_s=5) > 0\n            y[:,:,0] = get_mask(get_centroids(window), (256, 256), point_s=5) > 0\n            \n        x1 = torch.from_numpy(x1)\n        x1[:,:,4:] = onehot[(no_bedrooms, no_bathrooms)]\n        x1 = x1.permute(2, 0, 1).float()\n        \n        return x1, torch.from_numpy(x2).permute(2, 0, 1).float(), torch.from_numpy(y).permute(2, 0, 1).float(), state\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:19:45.319260Z","iopub.execute_input":"2023-09-13T01:19:45.319741Z","iopub.status.idle":"2023-09-13T01:19:45.449273Z","shell.execute_reply.started":"2023-09-13T01:19:45.319701Z","shell.execute_reply":"2023-09-13T01:19:45.448109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef plot_eight(images):\n    width = 256\n    height = 256\n    rows = 2\n    cols = 4\n    fig = plt.figure(figsize=(12, 8))  # Set the width and height as desired\n    fig.suptitle(\"Polygon Perturbation + Transformation + Rotational Noise\", fontsize=16)  # Add the title to the whole plot\n    axes = []\n\n\n    for i, image in enumerate(images):\n        image = cv2.resize((image.numpy() * 255).astype(np.uint8), (512, 512))\n        a, b = aug_prefs[i]\n#         a = 0\n#         b = 0\n        axes.append(fig.add_subplot(rows, cols, i + 1))\n        axes[-1].set_title(\"Rotation: \" + str(a) + \" | Flip X: \" + (\"True\" if b else \"False\"))\n        axes[-1]\n        plt.imshow(image)\n#     \n    fig.tight_layout()\n    plt.figure(figsize=(30, 30))\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:19:45.451178Z","iopub.execute_input":"2023-09-13T01:19:45.451892Z","iopub.status.idle":"2023-09-13T01:19:45.463347Z","shell.execute_reply.started":"2023-09-13T01:19:45.451850Z","shell.execute_reply":"2023-09-13T01:19:45.461947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"itt = iter(PlanDataset([plans[7]]))\nr = next(iter(itt))\nplt.imshow(r[0].permute((1, 2, 0))[:, :, [1, 2, 3]])\nplt.show()\nplt.imshow(r[2].permute((1, 2, 0))[:, :, 0])\nplt.show()\nplt.imshow(r[1].permute((1, 2, 0))[:, :, 0])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:19:45.467247Z","iopub.execute_input":"2023-09-13T01:19:45.467590Z","iopub.status.idle":"2023-09-13T01:19:46.174420Z","shell.execute_reply.started":"2023-09-13T01:19:45.467561Z","shell.execute_reply":"2023-09-13T01:19:46.173315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom segmentation_models_pytorch import Unet\nfrom segmentation_models_pytorch.encoders import get_encoder\nfrom segmentation_models_pytorch.decoders.unet.decoder import UnetDecoder\nfrom segmentation_models_pytorch.base import SegmentationModel, SegmentationHead\nfrom segmentation_models_pytorch.base.modules import Activation\nfrom segmentation_models_pytorch.base import Conv2dReLU\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings('ignore')\nimport segmentation_models_pytorch as smp\nimport torch\nimport torch.nn as nn\nimport segmentation_models_pytorch as smp\nfrom efficientnet_pytorch.utils import Conv2dStaticSamePadding\nimport torch\nfrom torchvision import models\nfrom torch import nn\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import DataLoader,Dataset\nfrom torchvision import transforms\nfrom torch import nn\nimport cv2\nimport pytorch_lightning as pl\nimport torch\nfrom sklearn.model_selection import train_test_split\nimport torchvision\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom pytorch_lightning import Trainer\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:19:46.175943Z","iopub.execute_input":"2023-09-13T01:19:46.176997Z","iopub.status.idle":"2023-09-13T01:19:51.246032Z","shell.execute_reply.started":"2023-09-13T01:19:46.176954Z","shell.execute_reply":"2023-09-13T01:19:51.244820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nclass CustomUnetPlusPlus(smp.UnetPlusPlus):\n    def __init__(self, encoder_name='efficientnet-b7', encoder_weights='imagenet', in_channels=20, classes=1):\n        super().__init__(encoder_name=encoder_name, encoder_weights=encoder_weights, in_channels=in_channels, classes=classes)\n        \n\n# model_2 = CustomUnetPlusPlus().cuda()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:19:51.247672Z","iopub.execute_input":"2023-09-13T01:19:51.248385Z","iopub.status.idle":"2023-09-13T01:19:51.256464Z","shell.execute_reply.started":"2023-09-13T01:19:51.248333Z","shell.execute_reply":"2023-09-13T01:19:51.254743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass DeepDecoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(2560, 1280, kernel_size=3, stride=2, padding=1)\n        self.conv2 = nn.Conv2d(1280, 720, kernel_size=3, stride=2, padding=1)\n        self.convTrans1 = nn.ConvTranspose2d(720, 640, kernel_size=2, stride=2)\n        self.convTrans2 = nn.ConvTranspose2d(640, 320, kernel_size=2, stride=2)\n        self.convTrans3 = nn.ConvTranspose2d(320, 160, kernel_size=2, stride=2)\n        self.convTrans4 = nn.ConvTranspose2d(160, 80, kernel_size=2, stride=2)\n        self.convTrans5 = nn.ConvTranspose2d(80, 1, kernel_size=2, stride=2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.convTrans1(x))\n        x = F.relu(self.convTrans2(x))\n        x = F.relu(self.convTrans3(x))\n        x = F.relu(self.convTrans4(x))\n        x = self.convTrans5(x)  # No activation on final layer\n        return x\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:19:51.259479Z","iopub.execute_input":"2023-09-13T01:19:51.259971Z","iopub.status.idle":"2023-09-13T01:19:51.279343Z","shell.execute_reply.started":"2023-09-13T01:19:51.259925Z","shell.execute_reply":"2023-09-13T01:19:51.278262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Encoder(nn.Module):\n    def __init__(self, inch=3, outch=512):\n        super().__init__()\n        self.conv1 = nn.Conv2d(inch, 64, kernel_size=3, stride=2, padding=1)\n        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)\n        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n        self.conv5 = nn.Conv2d(512, outch, kernel_size=3, stride=1, padding=1)\n\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        x = F.relu(self.conv4(x))\n        x = F.relu(self.conv5(x))\n        return x\n    \n    \nclass DecoderCNN2(nn.Module):\n    def __init__(self, inch=2560, outch=1):\n        super(DecoderCNN2, self).__init__()\n        \n        self.conv1 = nn.Conv2d(2560, 512, kernel_size=3, padding=1) \n        self.bn1 = nn.BatchNorm2d(512)\n        self.conv2 = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(256)\n        self.conv3 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n        self.bn3 = nn.BatchNorm2d(128)  \n        self.conv4 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n        self.bn4 = nn.BatchNorm2d(64)\n        self.conv5 = nn.Conv2d(64, 1, kernel_size=3, padding=1)\n\n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x))) \n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = F.relu(self.bn4(self.conv4(x)))\n        x = self.conv5(x)\n        return torch.sigmoid(F.interpolate(x, size=(256, 256)))\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:28:13.041528Z","iopub.execute_input":"2023-09-13T01:28:13.041964Z","iopub.status.idle":"2023-09-13T01:28:13.062470Z","shell.execute_reply.started":"2023-09-13T01:28:13.041919Z","shell.execute_reply":"2023-09-13T01:28:13.061300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nn.Conv2d(32, 1, kernel_size=3, padding=1)(torch.zeros((1, 32 , 32, 32))).shape","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:28:13.763546Z","iopub.execute_input":"2023-09-13T01:28:13.764533Z","iopub.status.idle":"2023-09-13T01:28:13.776006Z","shell.execute_reply.started":"2023-09-13T01:28:13.764479Z","shell.execute_reply":"2023-09-13T01:28:13.774340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.nn import LSTM\nimport torchvision\n\nimport torch\nimport torch.nn as nn\n\nclass DecoderCNN(nn.Module):\n    def __init__(self):\n       super().__init__()\n        \n       self.conv1 = nn.Conv2d(2560, 2048, kernel_size=3, padding=1)\n       self.bn1 = nn.BatchNorm2d(2048)\n    \n\n       self.deconv1 = nn.ConvTranspose2d(2048, 512, kernel_size=4, stride=2, padding=1, output_padding=0)\n       self.bn3 = nn.BatchNorm2d(512)\n\n       self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, output_padding=0)  \n       self.bn4 = nn.BatchNorm2d(256)\n       \n       self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, output_padding=0)\n       self.bn5 = nn.BatchNorm2d(128)\n\n       self.conv3 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n       self.conv4 = nn.Conv2d(64, 16, kernel_size=3, padding=1)\n       self.conv5 = nn.Conv2d(16, 1, kernel_size=3, padding=1)\n\n    def forward(self, x):\n       # Encoder \n       x = F.relu(self.bn1(self.conv1(x)))         \n       x = F.relu(self.bn3(self.deconv1(x)))\n       x = F.relu(self.bn4(self.deconv2(x)))  \n       x = F.relu(self.bn5(self.deconv3(x)))\n       x =  F.relu(self.conv3(x))\n       x =  F.relu(self.conv4(x))\n       x = torch.sigmoid(self.conv5(x))\n        \n       return x\n\n\nclass DecoderCNN(nn.Module):\n    def __init__(self):\n       super().__init__()\n        \n       self.conv1 = nn.Conv2d(2560, 2048, kernel_size=3, padding=1)\n       self.bn1 = nn.BatchNorm2d(2048)\n    \n\n       self.deconv1 = nn.ConvTranspose2d(2048, 64, kernel_size=4, stride=2, padding=1, output_padding=0)\n       self.bn3 = nn.BatchNorm2d(64)\n\n       self.deconv2 = nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1, output_padding=0)  \n       self.bn4 = nn.BatchNorm2d(32)\n       \n       self.deconv3 = nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1, output_padding=0)\n       self.bn5 = nn.BatchNorm2d(16)\n\n       self.conv3 = nn.Conv2d(16, 1, kernel_size=3, padding=1)\n\n    def forward(self, x):\n       # Encoder \n       x = F.relu(self.bn1(self.conv1(x)))         \n       x = F.relu(self.bn3(self.deconv1(x)))\n       x = F.relu(self.bn4(self.deconv2(x)))  \n       x = F.relu(self.bn5(self.deconv3(x)))\n       x = torch.sigmoid(self.conv3(x))\n        \n       return x\n\nclass BedCentRegressor(pl.LightningModule):\n    def __init__(self, model=None, criterion=None, use_res=True, inch=12, outch=1):\n        \n        super().__init__()\n        ENCODER = 'resnet50'\n        ENCODER_WEIGHTS = None\n        ACTIVATION = None\n        model = torch.load('/kaggle/input/bedrooms-last-10-4/model_centers_bed__100.pth', map_location=torch.device('cpu'))\n        model.model.backbone.conv1 = nn.Conv2d(inch, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n        model.model.classifier[4] = nn.Conv2d(256, outch, kernel_size=(1, 1), stride=(1, 1))\n    \n        self.model = model.cuda()\n        \n#         preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n\n        if criterion is None:\n            criterion = nn.MSELoss()\n        self.loss_func = criterion \n    \n    def forward(self, x):\n        x = self.model(x)\n        return x\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        sch = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n        return {\n            \"optimizer\": optimizer,\n            \"lr_scheduler\": {\n                \"scheduler\": sch,\n                \"monitor\": \"train_loss\",\n            }\n        }\n    \n    def training_step(self, batch, batch_idx):\n        inputs, labels = batch\n        outputs = self(inputs)\n        loss = self.loss_func(outputs, labels)\n        self.log(\"train_loss\", loss, on_epoch=True)\n        return loss\n\n    \n    def validation_step(self, batch, batch_idx):\n        inputs, labels = batch\n        outputs = self(inputs)\n        loss = self.loss_func(outputs, labels)\n        self.log(\"val_loss\", loss, on_epoch=True)\n\n        # store an example output and label\n        self.example_input = inputs[0]\n        self.example_output = outputs[0]\n        self.example_label = labels[0]\n\n        return loss\n\n    def on_train_epoch_end(self):\n        print(f\"Epoch: {self.current_epoch}\")\n        print(f\"Train Loss: {self.trainer.callback_metrics['train_loss']}\")\n        print(f\"Validation Loss: {self.trainer.callback_metrics['val_loss']}\")\n        \n        plt.imshow(self.example_input.detach().cpu().permute((1, 2, 0))[:, :, [1, 4, 3]])\n        plt.show()\n        plt.imshow(self.example_label.detach().cpu().permute((1, 2, 0))[:, :, :])\n        plt.show()\n        plt.imshow(self.example_output.detach().cpu().permute((1, 2, 0))[:, :, 0])\n        plt.show()\n\n\n\nclass DecoderCNN(nn.Module):\n    def __init__(self):\n       super().__init__()\n        \n       self.conv1 = nn.Conv2d(2560, 2048, kernel_size=3, padding=1)\n       self.bn1 = nn.BatchNorm2d(2048)\n    \n\n       self.deconv1 = nn.ConvTranspose2d(2048, 512, kernel_size=4, stride=2, padding=1, output_padding=0)\n       self.bn3 = nn.BatchNorm2d(512)\n\n       self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, output_padding=0)  \n       self.bn4 = nn.BatchNorm2d(256)\n       \n       self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, output_padding=0)\n       self.bn5 = nn.BatchNorm2d(128)\n\n       self.conv3 = nn.Conv2d(128, 1, kernel_size=3, padding=1)\n\n\n    def forward(self, x):\n       # Encoder \n       x = F.relu(self.bn1(self.conv1(x)))         \n       x = F.relu(self.bn3(self.deconv1(x)))\n       x = F.relu(self.bn4(self.deconv2(x)))  \n       x = F.relu(self.bn5(self.deconv3(x)))\n       x = torch.sigmoid(self.conv3(x))\n        \n       return x\n        \nclass BedCentRegressor2(pl.LightningModule):\n    def __init__(self, inch=12, state=None):\n        super().__init__()\n        \n        self.state = state\n\n        model = torch.load('/kaggle/input/bedrooms-last-10-4/model_centers_bed__100.pth', map_location=torch.device('cpu'))\n        model.model.backbone.conv1 = nn.Conv2d(inch, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n        cent_model_encoder = torch.nn.Sequential(*(list(model.model.children())[:-2]))\n        \n        self.encoder_main = cent_model_encoder\n        self.encoder_mini = Encoder(inch=3)\n\n        self.decoder_aio = DecoderCNN()\n        self.decoder_bed = DecoderCNN()\n        self.decoder_bath = DecoderCNN()\n        self.decoder_kit = DecoderCNN()\n        \n        \n        self.loss_func =  nn.MSELoss() \n        \n    def set_state(self, state):\n        self.state = state\n    \n    def forward_encoder_main(self, x):\n        return self.encoder_main(x)[\"out\"]\n    \n    def forward_encoder_mini(self, x):\n        return self.encoder_mini(x)  \n    \n    def forward_decoder(self, x1, x2, state=None):\n        x = torch.cat([x1, x2], dim=1)\n        if state == None:\n            x = self.decoder_aio(x)\n        if state == 1:\n            x = self.decoder_bed(x)        \n        elif state == 2:\n            x = self.decoder_bath(x)    \n        elif state == 3:\n            x = self.decoder_kit(x)\n        return x\n        \n    def forward(self, x1, x2):\n        x1 = self.encoder_main(x1)[\"out\"]\n        x2 = self.encoder_mini(x2)\n        x = torch.cat([x1, x2], dim=1)\n        \n        if self.state == None:\n            x = self.decoder_aio(x)\n        if self.state == 1:\n            x = self.decoder_bed(x)        \n        elif self.state == 2:\n            x = self.decoder_bath(x)    \n        elif self.state == 3:\n            x = self.decoder_kit(x)\n\n        return x\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        sch = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n        return {\n            \"optimizer\": optimizer,\n            \"lr_scheduler\": {\n                \"scheduler\": sch,\n                \"monitor\": \"train_loss\",\n            }\n        }\n    \n    def training_step(self, batch, batch_idx):\n        inputs_1, inputs_2, labels, state = batch\n        outputs = self(inputs_1, inputs_2)\n        loss = self.loss_func(outputs, labels)\n        self.log(\"train_loss\", loss, on_epoch=True)\n        return loss\n\n    \n    def validation_step(self, batch, batch_idx):\n        inputs_1, inputs_2, labels, state = batch\n        outputs = self(inputs_1, inputs_2)\n        loss = self.loss_func(outputs, labels)\n        self.log(\"val_loss\", loss, on_epoch=True)\n\n        # store an example output and label\n        self.example_input_1 = inputs_1[0]\n        self.example_input_2 = inputs_2[0]\n        self.example_output = outputs[0]\n        self.example_label = labels[0]\n\n        return loss\n\n    def on_train_epoch_end(self):\n        print(f\"Epoch: {self.current_epoch}\")\n        print(f\"Train Loss: {self.trainer.callback_metrics['train_loss']}\")\n        print(f\"Validation Loss: {self.trainer.callback_metrics['val_loss']}\")\n        \n        plt.imshow(self.example_input_1.detach().cpu().permute((1, 2, 0))[:, :, [1, 2, 3]])\n        plt.show()        \n        plt.imshow(self.example_input_2.detach().cpu().permute((1, 2, 0))[:, :, [0, 1, 2]])\n        plt.show()\n        plt.imshow(self.example_label.detach().cpu().permute((1, 2, 0))[:, :, :])\n        plt.show()\n        plt.imshow(self.example_output.detach().cpu().permute((1, 2, 0))[:, :, 0])\n        plt.show()\n#         plt.imshow(self.example_output.detach().cpu().permute((1, 2, 0))[:, :, 1])\n#         plt.show()\n#         plt.imshow(self.example_output.detach().cpu().permute((1, 2, 0))[:, :, 2])\n#         plt.show()\n        \n\n# class DecoderCNN(nn.Module):\n#     def __init__(self):\n#         super(DecoderCNN, self).__init__()\n        \n#         # Encoder layers\n#         self.conv1 = nn.Conv2d(2560, 512, kernel_size=4, padding=1)\n#         self.bn1 = nn.BatchNorm2d(512)\n        \n#         self.conv2 = nn.Conv2d(512, 256, kernel_size=4, padding=1)\n#         self.bn2 = nn.BatchNorm2d(256)\n\n#         # Decoder layers\n#         self.deconv1 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=3, padding=2)\n#         self.bn3 = nn.BatchNorm2d(128)\n\n#         self.deconv2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=3, padding=2)\n#         self.bn4 = nn.BatchNorm2d(64)\n\n#         self.conv3 = nn.Conv2d(64, 1, kernel_size=3, padding=1)\n\n#     def forward(self, x):\n#         x = F.relu(self.bn1(self.conv1(x)))\n#         x = F.relu(self.bn2(self.conv2(x)))\n\n#         x = F.relu(self.bn3(self.deconv1(x)))\n#         x = F.relu(self.bn4(self.deconv2(x)))\n\n#         x = self.conv3(x)\n#         return x","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:28:14.080671Z","iopub.execute_input":"2023-09-13T01:28:14.081072Z","iopub.status.idle":"2023-09-13T01:28:14.152491Z","shell.execute_reply.started":"2023-09-13T01:28:14.081036Z","shell.execute_reply":"2023-09-13T01:28:14.151363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DecoderCNN()(torch.zeros([1, 2560, 32, 32])).shape","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:28:14.778515Z","iopub.execute_input":"2023-09-13T01:28:14.779301Z","iopub.status.idle":"2023-09-13T01:28:17.569975Z","shell.execute_reply.started":"2023-09-13T01:28:14.779254Z","shell.execute_reply":"2023-09-13T01:28:17.568759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RoomLayoutUNet(nn.Module):\n    def __init__(self, n_channels=4, n_classes=11):\n        super(RoomLayoutUNet, self).__init__()\n        self.model = models.segmentation.deeplabv3_resnet101(pretrained=True, progress=True).cuda()\n        print(self.model.backbone.conv1)\n        self.model.backbone.conv1 = nn.Conv2d(n_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False).cuda()\n        self.model.classifier[4] = nn.Conv2d(256, n_classes, kernel_size=(1, 1), stride=(1, 1)).cuda()\n        self.embedding = nn.Embedding(5, 1).cuda()\n\n    def forward(self, x):\n        output = self.model(x)['out']\n        return output\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:28:17.572463Z","iopub.execute_input":"2023-09-13T01:28:17.572950Z","iopub.status.idle":"2023-09-13T01:28:17.583449Z","shell.execute_reply.started":"2023-09-13T01:28:17.572909Z","shell.execute_reply":"2023-09-13T01:28:17.582218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = BedCentRegressor2().load_from_checkpoint(\"/kaggle/input/blacdoorwindow/xxyy_t/epoch=45-step=21114.ckpt\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:28:17.585182Z","iopub.execute_input":"2023-09-13T01:28:17.585584Z","iopub.status.idle":"2023-09-13T01:28:42.637335Z","shell.execute_reply.started":"2023-09-13T01:28:17.585544Z","shell.execute_reply":"2023-09-13T01:28:42.634937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.decoder_bed = DecoderCNN()\n# model.decoder_bath = DecoderCNN()\n# model.decoder_kit = DecoderCNN()\n# model.decoder_aio = DecoderCNN()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:28:42.640528Z","iopub.execute_input":"2023-09-13T01:28:42.646434Z","iopub.status.idle":"2023-09-13T01:28:42.657084Z","shell.execute_reply.started":"2023-09-13T01:28:42.646365Z","shell.execute_reply":"2023-09-13T01:28:42.654299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trainer.save_checkpoint(\"final.ckpt\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.002294Z","iopub.execute_input":"2023-09-13T01:20:18.002802Z","iopub.status.idle":"2023-09-13T01:20:18.014545Z","shell.execute_reply.started":"2023-09-13T01:20:18.002723Z","shell.execute_reply":"2023-09-13T01:20:18.013104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for param in model.encoder_main.parameters():\n    param.requires_grad = False\n    \nfor param in model.encoder_mini.parameters():\n    param.requires_grad = True \n    \nfor param in model.decoder_bed.parameters():\n    param.requires_grad = True  \n    \nfor param in model.decoder_kit.parameters():\n    param.requires_grad = True   \n    \nfor param in model.decoder_bath.parameters():\n    param.requires_grad = True\n    \nmodel.decoder_bed = None\nmodel.decoder_bath = None\nmodel.decoder_kit = None\n# model.decoder_bath.load_state_dict(model.decoder_bed.state_dict())\n# model.decoder_kit.load_state_dict(model.decoder_bed.state_dict())","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:28:42.659028Z","iopub.execute_input":"2023-09-13T01:28:42.662361Z","iopub.status.idle":"2023-09-13T01:28:42.757340Z","shell.execute_reply.started":"2023-09-13T01:28:42.662317Z","shell.execute_reply":"2023-09-13T01:28:42.755746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model;","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:28:42.790436Z","iopub.execute_input":"2023-09-13T01:28:42.792460Z","iopub.status.idle":"2023-09-13T01:28:42.803171Z","shell.execute_reply.started":"2023-09-13T01:28:42.792399Z","shell.execute_reply":"2023-09-13T01:28:42.801500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import collections\nfrom pytorch_lightning.loggers import Logger\nfrom pytorch_lightning.utilities import rank_zero_only\n\nclass HistoryLogger(Logger):\n    def __init__(self):\n        super().__init__()\n        self.history = collections.defaultdict(list)\n\n    @property\n    def name(self):\n        return \"HistoryLogger\"\n\n    @property\n    def version(self):\n        return \"1.0\"\n\n    @rank_zero_only\n    def log_hyperparams(self, params):\n        # store hyperparameters in the history if you want\n        self.history['hyperparams'] = vars(params)\n\n    @rank_zero_only\n    def log_metrics(self, metrics, step):\n        for metric_name, metric_value in metrics.items():\n            self.history[metric_name].append(metric_value)\n            \nlogger = HistoryLogger()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:28:46.046446Z","iopub.execute_input":"2023-09-13T01:28:46.047174Z","iopub.status.idle":"2023-09-13T01:28:46.056402Z","shell.execute_reply.started":"2023-09-13T01:28:46.047113Z","shell.execute_reply":"2023-09-13T01:28:46.055226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cent_model = BedCentRegressor(inch=7, outch=3)\n# # cent_model.model.model.backbone.conv1 = nn.Conv2d(7, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n# # cent_model.model.model.classifier[4] = nn.Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n# cent_model.load_state_dict(torch.load(\"/kaggle/input/blacdoorwindow/xxyy_2/epoch=11-step=8016.ckpt\")[\"state_dict\"])\n# cent_model.cuda();","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:28:46.721338Z","iopub.execute_input":"2023-09-13T01:28:46.721729Z","iopub.status.idle":"2023-09-13T01:28:46.727416Z","shell.execute_reply.started":"2023-09-13T01:28:46.721695Z","shell.execute_reply":"2023-09-13T01:28:46.726108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cent_model.model.model.backbone.conv1 = nn.Conv2d(12, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n# cent_model.model.model.classifier[4] = nn.Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:28:47.157284Z","iopub.execute_input":"2023-09-13T01:28:47.158301Z","iopub.status.idle":"2023-09-13T01:28:47.163680Z","shell.execute_reply.started":"2023-09-13T01:28:47.158241Z","shell.execute_reply":"2023-09-13T01:28:47.162598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cent_model.model.model.backbone.conv1 = nn.Conv2d(12, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:28:47.442225Z","iopub.execute_input":"2023-09-13T01:28:47.442965Z","iopub.status.idle":"2023-09-13T01:28:47.447922Z","shell.execute_reply.started":"2023-09-13T01:28:47.442924Z","shell.execute_reply":"2023-09-13T01:28:47.446838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc, torch\n\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:28:50.393079Z","iopub.execute_input":"2023-09-13T01:28:50.393619Z","iopub.status.idle":"2023-09-13T01:28:50.814345Z","shell.execute_reply.started":"2023-09-13T01:28:50.393572Z","shell.execute_reply":"2023-09-13T01:28:50.813179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trainer.save_checkpoint(\"aio_last.ckpt\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:28:52.206946Z","iopub.execute_input":"2023-09-13T01:28:52.208107Z","iopub.status.idle":"2023-09-13T01:28:52.213387Z","shell.execute_reply.started":"2023-09-13T01:28:52.208055Z","shell.execute_reply":"2023-09-13T01:28:52.212029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.encoder_mini.conv1 = nn.Conv2d(6, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:28:53.107119Z","iopub.execute_input":"2023-09-13T01:28:53.108341Z","iopub.status.idle":"2023-09-13T01:28:53.113784Z","shell.execute_reply.started":"2023-09-13T01:28:53.108271Z","shell.execute_reply":"2023-09-13T01:28:53.112705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def get_width(p):\n    x1, y1, x2, y2 = p['inner'].bounds\n    return max(x2-x1, y2-y1)\n\nplans = [p for p in plans if get_width(p) <= 256]\nplan_all = plans\ntrain_plans, test_plans = train_test_split(plan_all, test_size=0.1, shuffle=True, random_state=1997)\n\nbatch = 32\n\nv=1\n\ntrain_plans = [i for i in train_plans if i['front_door'] and i['bedroom'] and i['bathroom'] and i['general'] ]\ntest_plans = [i for i in test_plans if i['front_door'] and i['bedroom'] and i['bathroom'] and  i['general'] ]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:29:14.810423Z","iopub.execute_input":"2023-09-13T01:29:14.810839Z","iopub.status.idle":"2023-09-13T01:29:16.007313Z","shell.execute_reply.started":"2023-09-13T01:29:14.810797Z","shell.execute_reply":"2023-09-13T01:29:16.006057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"state =  4\n\n\ntrain_dl = DataLoader(PlanDataset(train_plans, state=state), batch_size=batch, shuffle=True,num_workers=2)\nval_dl = DataLoader(PlanDataset(test_plans, state=state, val=v), batch_size=batch, shuffle=True, num_workers=2)\n\nmodel.set_state(None)\n\ncheckpoint = ModelCheckpoint(dirpath='xxyy', monitor=\"val_loss\", mode=\"min\")\n\ntrainer = Trainer(max_epochs=1000, callbacks=[checkpoint], gpus=1, logger=logger, auto_lr_find=True)\ntrainer.fit(model, train_dl, val_dl)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:29:16.012984Z","iopub.execute_input":"2023-09-13T01:29:16.015892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cent_model = torchvision.models.segmentation.deeplabv3_resnet50(num_classes=1)\n# cent_model.backbone.conv1 = nn.Conv2d(9, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n# # cent_model.classifier[4] = nn.Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n# cent_model = cent_model.cuda()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.078078Z","iopub.status.idle":"2023-09-13T01:20:18.078927Z","shell.execute_reply.started":"2023-09-13T01:20:18.078644Z","shell.execute_reply":"2023-09-13T01:20:18.078672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cent_model = torch.load('/kaggle/input/bedrooms-last-10-4/model_centers_bed__100.pth')\ncent_model.model.backbone.conv1 = nn.Conv2d(9, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\ncent_model.model.classifier[4] = nn.Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\ncent_model = cent_model.cuda()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.080416Z","iopub.status.idle":"2023-09-13T01:20:18.081231Z","shell.execute_reply.started":"2023-09-13T01:20:18.080925Z","shell.execute_reply":"2023-09-13T01:20:18.080952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_fn = nn.MSELoss()\n\nfrom shapely.geometry import box\nimport geopandas as gpd\nfrom tqdm.notebook import tqdm\n\nlr=1e-4\n\n\ndef accuracy_2(y_true, y_pred):\n    numerator = torch.sum(((y_pred>0.2) * y_true).bool().float())\n    denominator = torch.sum(y_true)\n    accuracy = numerator / denominator\n    return accuracy\n\ntrain_loss = []\nval_loss = []\ntrain_acc = []\nval_acc = []\n\nlr = lr * 0.98\noptimizer = torch.optim.Adam(cent_model.parameters(), lr=lr)\n\nfor i in range(200_000):    \n    for k, data in tqdm(enumerate(train_dl)):\n        inputs, labels = data[0].cuda(), data[1].cuda()\n        outputs = cent_model(inputs)\n        loss = loss_fn(outputs[:, 0, :, :], labels[:, 0, :, :])   \n        train_acc.append(accuracy_2(labels, outputs).detach().cpu().item())\n        loss.backward()\n        optimizer.step()\n        train_loss.append(loss.detach().cpu().item())\n\n        del loss\n        del inputs\n        del labels\n        del outputs\n        torch.cuda.empty_cache()\n        gc.collect()\n\n        if k % 100 == 0:\n            lr = lr * 0.8\n            if lr <= 1e-5:\n                lr = 1e-5\n            optimizer = torch.optim.Adam(cent_model.parameters(), lr=lr)\n            with torch.no_grad():\n                for data in val_dl:\n                    inputs, labels = data[0].cuda(), data[1].cuda()\n                    outputs = cent_model(inputs)\n                    loss = loss_fn(outputs[:, 0, :, :], labels[:, 0, :, :])\n                    val_acc.append(accuracy_2(labels, outputs).detach().cpu().item())\n                    val_loss.append(loss.detach().cpu().item())\n\n                plt.imshow(inputs[0].detach().cpu().permute((1, 2, 0))[:, :, [1, 3, 4]])\n                plt.show()\n\n                plt.imshow(outputs[0].detach().cpu()[0])\n                plt.show()\n\n                plt.imshow(labels[0].detach().cpu()[0])\n                plt.show()\n\n                print(np.mean(train_loss))\n                print(np.mean(val_loss))            \n                print(np.mean(train_acc))\n                print(np.mean(val_acc))\n\n                train_loss = []\n                val_loss = []\n                train_acc = []\n                val_acc = []\n                \n    optimizer = torch.optim.Adam(cent_model.parameters(), lr=lr)\n#     torch.save(cent_model.cuda(), f'/kaggle/working/bedroom_.pth')","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.082739Z","iopub.status.idle":"2023-09-13T01:20:18.083557Z","shell.execute_reply.started":"2023-09-13T01:20:18.083283Z","shell.execute_reply":"2023-09-13T01:20:18.083312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc, torch\n\ndel loss\ndel inputs\ndel labels\ndel outputs\n\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.085011Z","iopub.status.idle":"2023-09-13T01:20:18.085861Z","shell.execute_reply.started":"2023-09-13T01:20:18.085581Z","shell.execute_reply":"2023-09-13T01:20:18.085609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del outputs\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.087306Z","iopub.status.idle":"2023-09-13T01:20:18.088100Z","shell.execute_reply.started":"2023-09-13T01:20:18.087820Z","shell.execute_reply":"2023-09-13T01:20:18.087848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del loss\ndel inputs\ndel outputs","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.089563Z","iopub.status.idle":"2023-09-13T01:20:18.090392Z","shell.execute_reply.started":"2023-09-13T01:20:18.090087Z","shell.execute_reply":"2023-09-13T01:20:18.090115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport subprocess\nfrom IPython.display import FileLink, display\n\ndef download_file(path, download_file_name):\n    os.chdir('/kaggle/working/')\n    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n    command = f\"zip {zip_name} {path} -r\"\n    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n    if result.returncode != 0:\n        print(\"Unable to run zip command!\")\n        print(result.stderr)\n        return\n    display(FileLink(f'{download_file_name}.zip'))","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.091836Z","iopub.status.idle":"2023-09-13T01:20:18.092654Z","shell.execute_reply.started":"2023-09-13T01:20:18.092374Z","shell.execute_reply":"2023-09-13T01:20:18.092401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"download_file(\"/kaggle/working/xxyy\", \"xxyy_70ep.zip\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.094098Z","iopub.status.idle":"2023-09-13T01:20:18.094906Z","shell.execute_reply.started":"2023-09-13T01:20:18.094634Z","shell.execute_reply":"2023-09-13T01:20:18.094661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ch","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.096366Z","iopub.status.idle":"2023-09-13T01:20:18.097176Z","shell.execute_reply.started":"2023-09-13T01:20:18.096876Z","shell.execute_reply":"2023-09-13T01:20:18.096904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(xxyy_model, \"70ep_xxyy_model.pth\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.098626Z","iopub.status.idle":"2023-09-13T01:20:18.099447Z","shell.execute_reply.started":"2023-09-13T01:20:18.099140Z","shell.execute_reply":"2023-09-13T01:20:18.099184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.plot(trainer.logger.history['train_loss_epoch'][1:], label='train_loss')\nplt.plot(trainer.logger.history['val_loss'][1:], label='val_loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.100892Z","iopub.status.idle":"2023-09-13T01:20:18.101717Z","shell.execute_reply.started":"2023-09-13T01:20:18.101433Z","shell.execute_reply":"2023-09-13T01:20:18.101462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint.best_model_path","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.103186Z","iopub.status.idle":"2023-09-13T01:20:18.103991Z","shell.execute_reply.started":"2023-09-13T01:20:18.103716Z","shell.execute_reply":"2023-09-13T01:20:18.103744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model = XXYYRegressor().load_from_checkpoint(checkpoint.best_model_path)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.105675Z","iopub.status.idle":"2023-09-13T01:20:18.106487Z","shell.execute_reply.started":"2023-09-13T01:20:18.106202Z","shell.execute_reply":"2023-09-13T01:20:18.106237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.set_grad_enabled(True)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.107918Z","iopub.status.idle":"2023-09-13T01:20:18.108733Z","shell.execute_reply.started":"2023-09-13T01:20:18.108453Z","shell.execute_reply":"2023-09-13T01:20:18.108480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(best_model, \"70ep_xxyy_model.pth\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.110182Z","iopub.status.idle":"2023-09-13T01:20:18.110983Z","shell.execute_reply.started":"2023-09-13T01:20:18.110703Z","shell.execute_reply":"2023-09-13T01:20:18.110730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\n\n\nfor epoch in range(num_epochs):\n    print(f'_________________________')\n\n    \n    model.eval() \n    running_loss = 0.0 \n    with torch.no_grad():  \n        for i, (inputs, labels) in tqdm(enumerate(test_dl)): \n            inputs, labels = inputs.cuda(), labels.cuda().float() / 60.0\n            outputs = model(inputs)  \n            loss = criterion(outputs, labels)  \n            running_loss += loss.item() * inputs.size(0) \n    epoch_loss = running_loss / len(test_dl.dataset)\n    print(outputs[0]*100, labels[0]*100)\n    print(f'Validation Loss: {epoch_loss:.4f}')\n    \n    if epoch_loss < best_loss:\n        best_loss = epoch_loss\n        torch.save(model.state_dict(), 'best_model.pth')\n        # torch.save(model.cuda(), f'/kaggle/working/model_bed_bath.pth')\n    display(FileLink(\"best_model.pth\"))\n\n        \n    model.train()  # set the model to training mode\n    running_loss = 0.0\n    for i, (inputs, labels) in tqdm(enumerate(train_dl), total=len(train_dl)):  # iterate over the training data\n        try:\n            inputs, labels = inputs.cuda(), labels.cuda().float() / 60.0\n            optimizer.zero_grad() \n            outputs = model(inputs) \n            loss = criterion(outputs, labels)\n            loss.backward()  \n            optimizer.step()  \n            running_loss += loss.item() * inputs.size(0) \n        except:\n            ...\n    epoch_loss = running_loss / len(train_dl.dataset)  \n    print(f'Train Loss: {epoch_loss:.4f}')\n    \n#     lr /= 3\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    \n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.112497Z","iopub.status.idle":"2023-09-13T01:20:18.113327Z","shell.execute_reply.started":"2023-09-13T01:20:18.113018Z","shell.execute_reply":"2023-09-13T01:20:18.113045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_2","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.114765Z","iopub.status.idle":"2023-09-13T01:20:18.115595Z","shell.execute_reply.started":"2023-09-13T01:20:18.115317Z","shell.execute_reply":"2023-09-13T01:20:18.115345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import copy\n\nclass CustomUnet(SegmentationModel):\n    def __init__(self, encoder_name=\"\", mini_encoder=None, encoder=None, decoder=None, concat_size=5, big_image_channels=0, decoders_num=6,**kwargs):\n        super().__init__()\n        if encoder is not None:\n            self.encoder = encoder\n        else:\n            self.encoder = get_encoder(encoder_name, **kwargs)\n            \n            \n        decoder_channels = (256, 128, 64, 32, 16)\n        \n        enc_channels = list(self.encoder.out_channels)\n        \n        enc_channels[-1] += concat_size + (64 if big_image_channels else 0)\n        \n        self.decoders = [UnetDecoder(\n                encoder_channels=enc_channels,\n                decoder_channels=decoder_channels,\n                n_blocks=5,\n                use_batchnorm=True,\n                center=True,\n                attention_type=None\n            ).cuda() for nn in range(decoders_num)]\n        \n        if decoder is not None:\n            for nn in range(decoders_num):\n                x = self.decoders[nn].load_state_dict(copy.deepcopy(decoder.state_dict()))\n                print(x)\n        self.segmentation_head = SegmentationHead(\n            in_channels=decoder_channels[-1],\n            out_channels=kwargs.get(\"classes\", 1),\n            activation=None,\n            kernel_size=3,\n        )\n        if big_image_channels and mini_encoder is None:\n            self.mask_encoder = MiniEncoder(big_image_channels)\n        elif mini_encoder is not None:\n            self.mask_encoder = mini_encoder\n        \n        else:\n            self.mask_encoder = None\n\n\n    def forward(self, x, float_tensor, bedn, other=None, decoder_n=0):\n        features = self.encoder(x)\n        float_tensor = float_tensor.view(-1, 1, 1, 1).expand_as(features[-1])[:, 0, :, :].unsqueeze(1)\n        onehot = torch.zeros(float_tensor.shape[0], 4, float_tensor.shape[2], float_tensor.shape[3]).cuda()\n        if self.mask_encoder is not None: \n            other_inputs = self.mask_encoder(other)\n            bottleneck = torch.cat((features[-1], float_tensor, bedn, other_inputs), 1)\n        else:\n            bottleneck = torch.cat((features[-1], float_tensor, bedn), 1)\n            \n        features[-1] = bottleneck\n        x = self.decoders[decoder_n](*features)\n        x = self.segmentation_head(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.117087Z","iopub.status.idle":"2023-09-13T01:20:18.117912Z","shell.execute_reply.started":"2023-09-13T01:20:18.117634Z","shell.execute_reply":"2023-09-13T01:20:18.117662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_2 = CustomUnetPlusPlus().cuda()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.119387Z","iopub.status.idle":"2023-09-13T01:20:18.120191Z","shell.execute_reply.started":"2023-09-13T01:20:18.119895Z","shell.execute_reply":"2023-09-13T01:20:18.119922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# model_2 = torch.load(\"/kaggle/input/unet-custom-first-bedroom/bedroom_second_unet_22.pth\").cuda()\n\n# for name, para in model_2.encoder.named_parameters():\n#      para.requires_grad = False\n        \n# model.encoder = model_2.encoder\n# orig_decoder = model_2.decoder\n# orig_decoder.center = model.decoder.center\n# orig_decoder.blocks[0] = model.decoder.blocks[0]\n# model.decoder = orig_decoder\n\n\n# for name, para in model.decoder.named_parameters():\n#      para.requires_grad = True","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.121644Z","iopub.status.idle":"2023-09-13T01:20:18.122454Z","shell.execute_reply.started":"2023-09-13T01:20:18.122169Z","shell.execute_reply":"2023-09-13T01:20:18.122197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.mask_encoder = MaskBranch(2).cuda()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.123878Z","iopub.status.idle":"2023-09-13T01:20:18.124698Z","shell.execute_reply.started":"2023-09-13T01:20:18.124418Z","shell.execute_reply":"2023-09-13T01:20:18.124445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\n# model_2 = torch.load('/kaggle/input/unet-custom-first-bedroom/bedroom_second_unet_1000.pth').cuda()\n# ","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.126163Z","iopub.status.idle":"2023-09-13T01:20:18.126969Z","shell.execute_reply.started":"2023-09-13T01:20:18.126687Z","shell.execute_reply":"2023-09-13T01:20:18.126714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# outputs = model(inputs, areas, bedn, bed1)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.128454Z","iopub.status.idle":"2023-09-13T01:20:18.129276Z","shell.execute_reply.started":"2023-09-13T01:20:18.128966Z","shell.execute_reply":"2023-09-13T01:20:18.128994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"0","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.130718Z","iopub.status.idle":"2023-09-13T01:20:18.131538Z","shell.execute_reply.started":"2023-09-13T01:20:18.131257Z","shell.execute_reply":"2023-09-13T01:20:18.131285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model =  torch.load(\"/kaggle/input/bedroom-second-stage-5-2023-v1/bed_second_stage_model.pth\", map_location=torch.device('cpu')).eval();\n# # model_aug.resnet.segmentation_head[0] = nn.Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n# model.resnet.encoder.conv1 = nn.Conv2d(12, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n# model.unet.encoder.conv1 = nn.Conv2d(13, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n# model = model.cuda()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.132979Z","iopub.status.idle":"2023-09-13T01:20:18.133813Z","shell.execute_reply.started":"2023-09-13T01:20:18.133527Z","shell.execute_reply":"2023-09-13T01:20:18.133556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !wget https://www.kaggleusercontent.com/kf/134768889/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..0PV9B-hHYb7wLzPN4Gkbpg.6vTv5WMXPs5joUBU5lY7VjgPXsuAqcA-4UQJrnrJWdMPb5gRr6_-bjz4gbGM1xJuXRgVOVbVP_1856_yNVk959xUSrRiSeiT6EfpVE2qMTqnSt5JUGx4g6XzTJGvyOpg77kIyUpSjQBJnQQbhaDBMS8AM1tLh5WiHhj-K2beXiUA3kK8J--FiuXGV37RFG8a2EXF12ip8ZDQSPHF-0v1zKwOJFg-tJI3-yG07d-j-McsH3gQ83FXYAIS8WtmhKpyiYVo2gvk9t8jn_M00dN9GOCX1vfCHVRE0M8lYhmHGS2gAjKwXJRd55D2w54gFEGz1m1UATunONOGrJ_KVTtVrswF5xrSdxdC2JKanVpjXQ7PMr1ms3J9S_05j_2mPk8aM9Mo8ikAs9XdX4ySu-PouZGBNK2AllIAw6e5FRnAJCXdKpHGcmNTNJRddz6QzljX4q5Z875y-ukb0zMmnUdpaYnIg10_KBe1N7pkiWlpaLDTmqROa6Il5UpdbMaf0x-5i8yQvo31kbg1dbS1E-zHm_V17Iyg9JxvZgBe88jdIeRozlBgcz1UWqPWMSus5xoF4uIM1BO6dau4edNTytq7PlUTFi8yJ-sChym6YVoXA0Lx_Qu-oKaeo1rPwKvg8TzjgGHFzdaDvAk2CjMb1uFuYHymTxpNnPkbNENa8fhjRa8.af3ApNarl3B5436LI-zGDw/bedroom_second_unet_16.pth","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.135310Z","iopub.status.idle":"2023-09-13T01:20:18.136113Z","shell.execute_reply.started":"2023-09-13T01:20:18.135835Z","shell.execute_reply":"2023-09-13T01:20:18.135863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n# model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n#     in_channels=10, out_channels=1, init_features=32, pretrained=False).cuda()\n\n# model = torch.load('/kaggle/input/second-room-rplan/bedroom_second_unet_16.pth').cuda()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.137579Z","iopub.status.idle":"2023-09-13T01:20:18.138404Z","shell.execute_reply.started":"2023-09-13T01:20:18.138101Z","shell.execute_reply":"2023-09-13T01:20:18.138129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.encoder1.enc1conv1 = nn.Conv2d(11, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False).cuda()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.139854Z","iopub.status.idle":"2023-09-13T01:20:18.140677Z","shell.execute_reply.started":"2023-09-13T01:20:18.140396Z","shell.execute_reply":"2023-09-13T01:20:18.140423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.encoder1.enc1conv1 = nn.Conv2d(10, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False).cuda()\n# model.conv = nn.Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1)).cuda()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.142110Z","iopub.status.idle":"2023-09-13T01:20:18.142931Z","shell.execute_reply.started":"2023-09-13T01:20:18.142651Z","shell.execute_reply":"2023-09-13T01:20:18.142680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_width(plan):\n    w = plan['inner'].bounds[2] - plan['inner'].bounds[0]\n    return w\n\nplans = [p for p in plans if get_width(p) <= 256]\n\ntrain_plans_o, test_plans_o = train_test_split(plans, test_size=0.02, shuffle=True, random_state=1997)\ntrain_plans_r, test_plans_r = train_test_split(rplans, test_size=0.02, shuffle=True, random_state=1997)\n\nbatch = 12\nv=0\ntrain_plans = [i for i in train_plans_o if i['front_door'] and i['bedroom'] and len(i['bedroom'].geoms)>= 1  and i['bathroom'] and i['general']]\ntest_plans = [i for i in test_plans_o if i['front_door'] and i['bedroom'] and len(i['bedroom'].geoms) >= 1  and i['bathroom'] and  i['general']]\nbed1_traindl = DataLoader(PlanDataset(train_plans, task='bed1'), batch_size=batch, shuffle=True,num_workers=2)\nbed1_valdl = DataLoader(PlanDataset(test_plans, task='bed1', val=v), batch_size=batch, shuffle=True, num_workers=2)\n\ntrain_plans = [i for i in train_plans_o if i['front_door'] and i['bedroom'] and len(i['bedroom'].geoms)>= 2 and i['bathroom'] and i['general'] ]\ntest_plans = [i for i in test_plans_o if i['front_door'] and i['bedroom'] and len(i['bedroom'].geoms)>= 2  and i['bathroom'] and  i['general']]\nbed2_traindl = DataLoader(PlanDataset(train_plans, task='bed2'), batch_size=batch, shuffle=True,num_workers=2)\nbed2_valdl = DataLoader(PlanDataset(test_plans, task='bed2', val=v), batch_size=batch, shuffle=True, num_workers=2)\n\ntrain_plans = [i for i in train_plans_o if i['front_door'] and i['bedroom'] and len(i['bedroom'].geoms) >= 3  and i['bathroom'] and i['general']]\ntest_plans = [i for i in test_plans_o if i['front_door'] and i['bedroom'] and len(i['bedroom'].geoms) >= 3  and i['bathroom'] and  i['general']]\nbed3_traindl = DataLoader(PlanDataset(train_plans, task='bed3'), batch_size=batch, shuffle=True,num_workers=2)\nbed3_valdl = DataLoader(PlanDataset(test_plans, task='bed3', val=v), batch_size=batch, shuffle=True, num_workers=2)\n\ntrain_plans = [i for i in train_plans_o if i['front_door'] and i['bedroom'] and len(i['bathroom'].geoms) >= 1  and i['bathroom'] and i['general'] ]\ntest_plans = [i for i in test_plans_o if i['front_door'] and i['bedroom'] and len(i['bathroom'].geoms) >= 1  and i['bathroom'] and  i['general']]\nbath1_traindl = DataLoader(PlanDataset(train_plans, task='bath1'), batch_size=batch, shuffle=True,num_workers=2)\nbath1_valdl = DataLoader(PlanDataset(test_plans, task='bath1', val=v), batch_size=batch, shuffle=True, num_workers=2)\n\ntrain_plans = [i for i in train_plans_o if i['front_door'] and i['bedroom'] and len(i['bathroom'].geoms) >= 2   and i['bathroom'] and i['general'] ]\ntest_plans = [i for i in test_plans_o if i['front_door'] and i['bedroom'] and len(i['bathroom'].geoms) >= 2  and i['bathroom'] and  i['general']]\nbath2_traindl = DataLoader(PlanDataset(train_plans, task='bath2'), batch_size=batch, shuffle=True,num_workers=2)\nbath2_valdl = DataLoader(PlanDataset(test_plans, task='bath2', val=v), batch_size=batch, shuffle=True, num_workers=2)\n\ntrain_plans = [i for i in train_plans_o if i['front_door'] and i['bedroom'] and len(i['bathroom'].geoms) >= 3   and i['bathroom'] and i['general']]\ntest_plans = [i for i in test_plans_o if i['front_door'] and i['bedroom'] and len(i['bathroom'].geoms) >= 3  and i['bathroom'] and  i['general']]\nbath3_traindl = DataLoader(PlanDataset(train_plans, task='bath3'), batch_size=batch, shuffle=True,num_workers=2)\nbath3_valdl = DataLoader(PlanDataset(test_plans, task='bath3', val=v), batch_size=batch, shuffle=True, num_workers=2)\n\ntrain_plans = [i for i in train_plans_r if i['front_door'] and i['bedroom'] and  i['bathroom'] and i['kitchen']]\ntest_plans = [i for i in test_plans_r if i['front_door'] and i['bedroom'] and i['bathroom'] and  i['kitchen']]\nkit_traindl = DataLoader(PlanDataset(train_plans[:47000], task='kit'), batch_size=batch, shuffle=True,num_workers=2)\nkit_valdl = DataLoader(PlanDataset(test_plans[:100], task='kit', val=v), batch_size=batch, shuffle=True, num_workers=2)\n\nlen(train_plans)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.144478Z","iopub.status.idle":"2023-09-13T01:20:18.145316Z","shell.execute_reply.started":"2023-09-13T01:20:18.144987Z","shell.execute_reply":"2023-09-13T01:20:18.145014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"train_plan_datasets = [bed1_traindl, bed2_traindl,bed3_traindl,bath1_traindl,bath2_traindl,bath3_traindl, kit_traindl]\nval_plan_datasets = [bed1_valdl, bed2_valdl,bed3_valdl,bath1_valdl,bath2_valdl,bath3_valdl, kit_valdl]\n\n[len(i) for i in train_plan_datasets] , [len(i) for i in val_plan_datasets] ","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.146778Z","iopub.status.idle":"2023-09-13T01:20:18.147588Z","shell.execute_reply.started":"2023-09-13T01:20:18.147310Z","shell.execute_reply":"2023-09-13T01:20:18.147338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max([len(i) for i in train_plan_datasets]), max([len(i) for i in val_plan_datasets])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.149016Z","iopub.status.idle":"2023-09-13T01:20:18.149829Z","shell.execute_reply.started":"2023-09-13T01:20:18.149550Z","shell.execute_reply":"2023-09-13T01:20:18.149577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import backend as K\n\ndef accuracy_2(y_true, y_pred):\n    numerator = torch.sum(((y_pred>0.2) * y_true).bool().float())\n    denominator = torch.sum(y_true)\n    accuracy = numerator / denominator\n    return accuracy > 0.5","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.151302Z","iopub.status.idle":"2023-09-13T01:20:18.152100Z","shell.execute_reply.started":"2023-09-13T01:20:18.151821Z","shell.execute_reply":"2023-09-13T01:20:18.151849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.153585Z","iopub.status.idle":"2023-09-13T01:20:18.154414Z","shell.execute_reply.started":"2023-09-13T01:20:18.154111Z","shell.execute_reply":"2023-09-13T01:20:18.154139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"i = random.randint(0, 31)\nx = next(iter(test_data))\n\nplt.imshow( model(x[0])[i] )\nplt.show()\nplt.imshow(x[0][i][:, :, 8:11] + 2* x[1][i][:, :, :])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-09T00:32:11.916071Z","iopub.status.idle":"2023-04-09T00:32:11.916605Z","shell.execute_reply.started":"2023-04-09T00:32:11.916332Z","shell.execute_reply":"2023-04-09T00:32:11.916367Z"}}},{"cell_type":"code","source":"ll = 1e-5","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.155850Z","iopub.status.idle":"2023-09-13T01:20:18.156687Z","shell.execute_reply.started":"2023-09-13T01:20:18.156406Z","shell.execute_reply":"2023-09-13T01:20:18.156434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ll = ll * 0.97\nll","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.158139Z","iopub.status.idle":"2023-09-13T01:20:18.158966Z","shell.execute_reply.started":"2023-09-13T01:20:18.158688Z","shell.execute_reply":"2023-09-13T01:20:18.158715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for name, para in model.encoder.named_parameters():\n#      para.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.160445Z","iopub.status.idle":"2023-09-13T01:20:18.161280Z","shell.execute_reply.started":"2023-09-13T01:20:18.160972Z","shell.execute_reply":"2023-09-13T01:20:18.160999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max([len(i) for  i in val_plan_datasets])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.162719Z","iopub.status.idle":"2023-09-13T01:20:18.163539Z","shell.execute_reply.started":"2023-09-13T01:20:18.163259Z","shell.execute_reply":"2023-09-13T01:20:18.163287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport uuid\n\nfrom matplotlib import pyplot as plt\n\nimport torch\nfrom typing import Iterable\n\nimport cv2\nimport numpy as np\nfrom pandas import Series\nfrom shapely.geometry import MultiPolygon, Polygon, Point, box\nimport matplotlib.pyplot as plt\nfrom skimage.feature import blob_dog, blob_log, blob_doh\nfrom skimage.color import rgb2gray\nfrom skimage import io\n\n\ndef imfy(img):\n    return (np.clip(img, 0, 1) * 255).astype(np.uint8)\n\n\ndef get_rects(imgr, centroids):\n    bounds = get_mask(centroids, point_s=8).astype(np.uint8)\n    img = (imgr).astype(np.uint8)\n    #     img[bounds>0] = 0\n\n    img[np.where(bounds == 0)] = 0\n    # plt.imshow(img)\n    # plt.show()\n\n    shapes = []\n    cnts = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    for i, c in enumerate(cnts[0]):\n        M = cv2.moments(c)\n        box = cv2.boundingRect(c);\n        x1, y1, w, h = box\n        x2, y2 = x1 + w, y1 + h\n\n        ii = img[y1:y2, x1:x2]\n\n        intensity = np.sum(ii > np.median(ii))\n\n        if not M[\"m00\"]:\n            continue\n        cx = M[\"m10\"] / M[\"m00\"]\n        cy = M[\"m01\"] / M[\"m00\"]\n        shapes.append([cx, cy, intensity])\n\n    return [Point(*i[:2]) for i in sorted(shapes, key=lambda x: x[2], reverse=True)]\n\n\ndef get_rects_2(channel, gcenters=True):\n    a = channel.copy()\n\n    a[a < 0.9] = 0\n    a[a > 1] = 1\n\n    a = (255 * a).astype(np.uint8)\n\n    _, thresh = cv2.threshold(a, 0, 255, cv2.THRESH_OTSU)\n\n    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n    final_c = []\n    centers = []\n    for c in contours:\n        perimeter = cv2.arcLength(c, True)\n        approx = cv2.approxPolyDP(c, 0.01 * perimeter, True)\n        x, y, w, h = cv2.boundingRect(approx)\n        shapely_box = box(x, y, x + w, y + h)\n        final_c.append(shapely_box.buffer(5, join_style=2, cap_style=2))\n\n        mask = np.zeros((256, 256))\n        mask = cv2.drawContours(mask, [c], -1, 255, -1)\n\n        rms = channel.copy()\n        rms[mask == 0] = 0\n\n        M = cv2.moments(rms)\n        cX = int(M[\"m10\"] / M[\"m00\"])\n        cY = int(M[\"m01\"] / M[\"m00\"])\n        centers.append(Point(cX, cY))\n\n    if gcenters:\n        return centers\n    return MultiPolygon(final_c).buffer(0)\n\n\n# def accuracy_2(y_true, y_pred):\n#     acc = []\n#     for i in range(len(y_true)):\n#         yt = y_true[i]\n#         yp = y_pred[i]\n#         yp = yp[0].detach().numpy()\n#         yt = yt[0].detach().numpy()\n#         im = imfy(yp)\n#         img = cv2.GaussianBlur(im, (15, 15), 5)\n#         blobs_log = blob_log(img, min_sigma=6, max_sigma=30, threshold=0.01)\n#         bed_centroids = [Point(i[1], i[0]) for i in blobs_log]\n#         try:\n#             bed_centroids = get_rects(im, bed_centroids)[0]\n#         except:\n#             bed_centroids = []\n#         bed_centroids_in = get_mask(bed_centroids, point_s=8)\n#         numerator = np.sum(((bed_centroids_in>0.2) * yt) > 0 )\n#         denominator = np.sum(yt)\n#         accuracy = numerator / denominator\n        \n#         acc.append(accuracy > 0.5)\n#     return np.mean(acc)\n\n\ndef accuracy_2(y_true, y_pred):\n    numerator = torch.sum(((y_pred>0.2) * y_true).bool().float())\n    denominator = torch.sum(y_true)\n    accuracy = numerator / denominator\n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.165169Z","iopub.status.idle":"2023-09-13T01:20:18.166006Z","shell.execute_reply.started":"2023-09-13T01:20:18.165726Z","shell.execute_reply":"2023-09-13T01:20:18.165753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for name, para in model_2.encoder.named_parameters():\n#     para.requires_grad = True\n    \n# for name, para in model_2.mask_encoder.named_parameters():\n#     para.requires_grad = True \n    \n# for dec in model_2.decoders:\n#     for name, para in dec.named_parameters():\n#         para.requires_grad = True \n    \n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.167489Z","iopub.status.idle":"2023-09-13T01:20:18.168323Z","shell.execute_reply.started":"2023-09-13T01:20:18.168008Z","shell.execute_reply":"2023-09-13T01:20:18.168036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    print(model_2.steps)\nexcept:\n    model_2.steps=0","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.169762Z","iopub.status.idle":"2023-09-13T01:20:18.170584Z","shell.execute_reply.started":"2023-09-13T01:20:18.170302Z","shell.execute_reply":"2023-09-13T01:20:18.170330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_2.steps","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.172018Z","iopub.status.idle":"2023-09-13T01:20:18.172858Z","shell.execute_reply.started":"2023-09-13T01:20:18.172575Z","shell.execute_reply":"2023-09-13T01:20:18.172603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\n\n\n# del inputs\n# del labels \n# del i\n# del d\n# del outputs\n# del train_loss \n# del val_loss \n# del train_acc \n# del val_acc\n# del loss\n\n\ngc.collect()\ntorch.cuda.empty_cache()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.174344Z","iopub.status.idle":"2023-09-13T01:20:18.175141Z","shell.execute_reply.started":"2023-09-13T01:20:18.174866Z","shell.execute_reply":"2023-09-13T01:20:18.174895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_fn = nn.MSELoss()\n\nfrom shapely.geometry import box\nimport geopandas as gpd\nimport pygeos\nimport tqdm\nfrom pygeos.creation import box\n\nlr=1e-4\n\nos.makedirs('sample_output', exist_ok=True)\nmodel_2 = model_2.train()\n\ntrain_loss = []\nval_loss = []\ntrain_acc = []\nval_acc = []\n\nt_itter = {i: [iter(val), val] for i, val in enumerate(train_plan_datasets)}\nlr = lr * 0.98\noptimizer = torch.optim.Adam(model_2.parameters(), lr=lr)\n\n# for i in tqdm.tqdm(range(200000)):\nfor i in range(200_000):\n    \n    epoch = i // 2000  \n    \n    for idx, (dit, dg) in t_itter.items():\n        optimizer.zero_grad()\n\n        try:\n            d = next(dit)\n        except:\n            dit = iter(dg)\n            t_itter[idx] = (dit, dg)\n            d = next(dit)\n        inputs, labels = d[0].cuda(), d[1].cuda()\n        outputs = model_2(inputs)\n        model_2.steps += 1\n        loss = loss_fn(outputs, labels)   \n\n        train_acc.append(accuracy_2(labels, outputs).detach().cpu().item())\n\n        loss.backward()\n        train_loss.append(loss.detach().cpu().item())\n        optimizer.step()\n\n\n    del inputs\n    del labels \n    del d\n    del loss\n    del outputs\n    gc.collect()\n    torch.cuda.empty_cache()\n    optimizer.step()\n\n\n    if i % 300 == 0:\n        lr = lr * 0.8\n        if lr <= 1e-5:\n            lr = 1e-5\n        optimizer = torch.optim.Adam(model_2.parameters(), lr=lr)\n        with torch.no_grad():\n            v_itter = {i: [iter(val), val] for i, val in enumerate(val_plan_datasets)}\n            for j in range(28):\n                for idx, (dit, dg) in v_itter.items():\n                    try:\n                        d = next(dit)\n                    except:\n                        dit = iter(dg)\n                        v_itter[idx] = (dit, dg)\n                        d = next(dit)\n                    inputs, labels = d[0].cuda(), d[1].cuda()\n\n                    outputs = model_2(inputs)\n                    loss = loss_fn(outputs, labels) \n                    val_loss.append(loss.detach().cpu().item())\n                    val_acc.append(accuracy_2(labels, outputs).detach().cpu().item())\n\n                    if j == 0:\n                        inp1 = inputs[0].permute(1, 2, 0).cpu().detach().numpy()[:,:,[19, 1, 18]]\n                        inp1[:, :, 1] = inp1[:, :, 1] - inp1[:, :, 0]\n                        inp1[:, :, 1] = inp1[:, :, 1] - inp1[:, :, 2]\n                        inp1[:, :, [0, 2]] += inputs[0].permute(1, 2, 0).cpu().detach().numpy()[:,:,[0, 0]]\n                        inp2 = labels[0].permute(1, 2, 0).cpu().detach().numpy()[:,:,:]\n                        inp3 = outputs[0].permute(1, 2, 0).cpu().detach().numpy()[:,:,:]\n\n#                             plt.imshow( inp1, origin='lower' )\n#                             plt.show()\n#                             plt.imshow( inp2, origin='lower' )\n#                             plt.show()\n#                             plt.imshow( inp3, origin='lower' )\n#                             plt.show()\n# create a figure and its subplots\n                        fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n\n                        # display each image on each subplot\n                        axs[0].imshow(inp1, cmap='inferno' )\n                        axs[1].imshow(inp2, cmap='inferno' )\n                        inp3[inp1[:, :, 0]>0] = 0\n                        inp3[inp1[:, :, 2]>0] = 0\n                        axs[2].imshow(inp3, cmap='inferno' )\n\n                        im = imfy(inp3)\n                        img = cv2.GaussianBlur(im, (15, 15), 5)\n                        blobs_log = blob_log(img, min_sigma=4, max_sigma=30, threshold=0.01)\n                        bed_centroids = [Point(i[1], i[0]) for i in blobs_log]\n                        try:\n                            bed_centroids = get_rects(im, bed_centroids, door)[0]\n                        except:\n                            bed_centroids = []\n                        bed_centroids_in = get_mask(bed_centroids, point_s=5)\n#                         plt.imshow( bed_centroids_in/, origin='lower')\n                        axs[3].imshow(bed_centroids_in, cmap='inferno' )\n\n                        plt.show()\n\n        print('Epoch {} - Train Loss: {:.6f} | Val Loss: {:.6f} | Train accuracy: {:.6f} | Val accuracy {:.6f} '.format(epoch+1, np.mean(train_loss), np.mean(val_loss), np.mean(train_acc), np.mean(val_acc)))\n        val_loss = []\n        train_loss = []\n        train_acc = []\n        val_acc = []\n\n\n#     if i % 100 == 0:\n#         torch.save(model_2.cuda(), f'/kaggle/working/bedroom_second_unet_{epoch}.pth')\n\n    if i%100 == 0:\n        optimizer = torch.optim.Adam(model_2.parameters(), lr=lr)\n        torch.save(model_2.cuda(), f'/kaggle/working/bedroom_{epoch}.pth')","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.176916Z","iopub.status.idle":"2023-09-13T01:20:18.177727Z","shell.execute_reply.started":"2023-09-13T01:20:18.177447Z","shell.execute_reply":"2023-09-13T01:20:18.177475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aa = inp3>0","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.179170Z","iopub.status.idle":"2023-09-13T01:20:18.179969Z","shell.execute_reply.started":"2023-09-13T01:20:18.179691Z","shell.execute_reply":"2023-09-13T01:20:18.179718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_2 = model_2.eval()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.181428Z","iopub.status.idle":"2023-09-13T01:20:18.182250Z","shell.execute_reply.started":"2023-09-13T01:20:18.181938Z","shell.execute_reply":"2023-09-13T01:20:18.181966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## inputs","metadata":{}},{"cell_type":"code","source":"# model_2.train();","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.183686Z","iopub.status.idle":"2023-09-13T01:20:18.184498Z","shell.execute_reply.started":"2023-09-13T01:20:18.184215Z","shell.execute_reply":"2023-09-13T01:20:18.184251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_input(inner, door, bedn, bathn, task, area, bedrooms=[], bathrooms=[]):\n\n    s = 0.8\n\n    perturb_range = 0\n\n\n    inner = perturb_polygon(inner , x_range=(-perturb_range, perturb_range), y_range=(-perturb_range, perturb_range)).buffer(0)\n\n    noif = 2\n\n        \n    no_bedrooms = bedn\n    no_bathrooms = bathn\n\n\n    x = np.zeros((256, 256, 20))\n\n    front = door.centroid\n    \n\n    bedroomsc = bedrooms\n    bathroomsc = bathrooms\n    \n    x[:,:,0] = get_mask(front, (256, 256), point_s=7) > 0\n    x[:,:,1] = get_mask(inner, (256, 256), point_s=10) > 0\n    \n    if 'kit' not in task:\n        x[:, :, nd[task] + 2] = 1.0 # 2, 3, 4, 5 ,6, 7\n\n    bed_start = 9 # 9 10 11\n    bath_start = 12 # 12 13 14\n    num_start = 15 # 15 16 17\n    bed_m, bath_m = 18, 19\n    \n    if 'bed' in task:\n        bnn = int(task[3])\n        x[:,:,bnn + bed_start - 1] = 1.0\n        x[:,:,num_start + no_bedrooms - 1][:bnn] = 1.0\n        x[:,:,bed_m] =  get_mask(bedroomsc[:bnn-1], (256, 256), point_s=6) > 0\n\n    elif 'bath' in task:\n        btn = int(task[4])\n        x[:,:,btn + bath_start - 1] = 1.0\n        x[:,:,num_start + no_bathrooms - 1] = 1.0\n        x[:,:,bath_m] =  get_mask(bathroomsc[:btn-1], (256, 256), point_s=6) > 0\n        x[:,:,bed_m] =  get_mask(bedroomsc, (256, 256), point_s=6) > 0\n\n    elif 'kit' in task:\n        x[:,:,bath_m] =  get_mask(bathroomsc, (256, 256), point_s=6) > 0\n        x[:,:,bed_m] =  get_mask(bedroomsc, (256, 256), point_s=6) > 0\n\n#     area += random.randint(-10, 10)\n\n    x[:,:,8] = norm_area(area)\n\n\n    return torch.from_numpy(x).permute(2, 0, 1).float()\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.185986Z","iopub.status.idle":"2023-09-13T01:20:18.186809Z","shell.execute_reply.started":"2023-09-13T01:20:18.186532Z","shell.execute_reply":"2023-09-13T01:20:18.186560Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_input_wh(current, inner, door, bedrooms=[], bathrooms=[], kitchen=[]):\n\n    s = 0.8\n\n\n    x = np.zeros((256, 256, 4))\n\n    front = door.centroid\n    \n\n    bedroomsc = bedrooms\n    bathroomsc = bathrooms\n    \n    x[:,:,0] = get_mask(front, (256, 256), point_s=7) > 0\n    x[:,:,1] = get_mask(inner, (256, 256), point_s=10) > 0\n    \n    data =  bedrooms + bathrooms + kitchen\n\n\n    x[:,:,2] =  get_mask(data, (256, 256), point_s=6) > 0\n    x[:,:,3] =  get_mask(current, (256, 256), point_s=6) > 0\n\n\n    return torch.from_numpy(x).permute(2, 0, 1).float()\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.188274Z","iopub.status.idle":"2023-09-13T01:20:18.189073Z","shell.execute_reply.started":"2023-09-13T01:20:18.188795Z","shell.execute_reply":"2023-09-13T01:20:18.188822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nfrom shapely.geometry import Point\nfrom shapely import from_wkt\n\ndef parse_points(s):\n    numbers = list(map(int, re.findall(r'\\d+', s)))\n    points = [Point(numbers[i:i+2]) for i in range(0, len(numbers), 2)]\n    \n    return points\n\n\n\na = \"\"\"\n[<POINT (59 156)>, <POINT (70 90)>]\n[<POINT (103 166)>, <POINT (131 75)>]\n[<POINT (132 165)>]\nPOLYGON ((230.4 84.78348415828609, 230.4 78.55408415068374, 205.48239996959055 78.55408415068374, 205.48239996959055 81.66878415448491, 230.2295366510251 81.66878415448491, 230.2295366510251 84.78348415828609, 230.4 84.78348415828609))\nPOLYGON ((32.03489108965486 64.93806732138222, 155.58480001102853 64.93806732138222, 155.58480001102853 81.66878415448491, 230.2295366510251 81.66878415448491, 230.2295366510251 191.06193267861778, 25.599999999999994 191.06193267861778, 25.599999999999994 112.5562613848283, 32.03489108965486 112.5562613848283, 32.03489108965486 64.93806732138222))\n\n\"\"\".split('\\n')\n\nd = [i for i in a if 'POL' in i]\ndoor, inner = min(d, key=lambda x: len(x)), max(d, key=lambda x: len(x))\ndoor = from_wkt(door)\ninner = from_wkt(inner)\n\np = [i for i in a if 'POI' in i]\nbed, bath, kit = [parse_points(i) for i in p]\n\nalless = bed + kit + bath\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.190566Z","iopub.status.idle":"2023-09-13T01:20:18.191382Z","shell.execute_reply.started":"2023-09-13T01:20:18.191078Z","shell.execute_reply":"2023-09-13T01:20:18.191106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"boxes = []\n\nmodel.eval()\nfor i in alless:\n    cx, cy = i.coords[0]\n    x = get_input_wh(i, inner, door, bed , bath , kit).unsqueeze(0)\n    \n    y = model(x).detach().cpu().numpy()[0]\n    \n    w, h = y*60\n    \n    x1, x2, y1, y2 = cx - w/2, cx +w/2, cy-h/2, cy+h/2 \n    b = box(x1, y1, x2, y2)\n    boxes.append(b)\n\nboxes = [i.intersection(inner.buffer(-3, join_style=2, cap_style=2)) for i in boxes]\n\nboxes = sorted(boxes, key=lambda x: x.area, reverse=True)\n\nfor i in range(len(boxes)-1):\n    new_b = boxes[i]\n    for j in range(i + 1, len(boxes)):\n        new_b = new_b.difference(boxes[j].buffer(3, join_style=2, cap_style=2))\n    boxes[i] = new_b.buffer(-5, join_style=2, cap_style=2).buffer(5, join_style=2, cap_style=2)\n    boxes[j] = boxes[j].buffer(-5, join_style=2, cap_style=2).buffer(5, join_style=2, cap_style=2)\n\n\ngpd.GeoSeries([inner] + boxes).plot(cmap=\"Dark2_r\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.192835Z","iopub.status.idle":"2023-09-13T01:20:18.193656Z","shell.execute_reply.started":"2023-09-13T01:20:18.193376Z","shell.execute_reply":"2023-09-13T01:20:18.193403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"boxes = []\n\nxxyy_model.eval()\nfor i in alless:\n    cx, cy = i.coords[0]\n    x = get_input_wh(i, inner, door, bed , bath , kit).cuda().unsqueeze(0)\n    \n    y = xxyy_model(x).detach().cpu().numpy()[0]\n    \n#     w, h = y*60\n    \n#     x1, x2, y1, y2 = cx - w/2, cx +w/2, cy-h/2, cy+h/2 \n    x1, y1, x2, y2 = y * 256\n    b = box(x1, y1, x2, y2)\n    boxes.append(b)\n\n# boxes = [i.intersection(inner.buffer(-3, join_style=2, cap_style=2)) for i in boxes]\n\n# boxes = sorted(boxes, key=lambda x: x.area, reverse=True)\n\n# for i in range(len(boxes)-1):\n#     new_b = boxes[i]\n#     for j in range(i + 1, len(boxes)):\n#         new_b = new_b.difference(boxes[j].buffer(3, join_style=2, cap_style=2))\n#     boxes[i] = new_b.buffer(-5, join_style=2, cap_style=2).buffer(5, join_style=2, cap_style=2)\n#     boxes[j] = boxes[j].buffer(-5, join_style=2, cap_style=2).buffer(5, join_style=2, cap_style=2)\n\n\ngpd.GeoSeries([inner] + boxes).plot(cmap=\"Dark2_r\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.195121Z","iopub.status.idle":"2023-09-13T01:20:18.195939Z","shell.execute_reply.started":"2023-09-13T01:20:18.195659Z","shell.execute_reply":"2023-09-13T01:20:18.195686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom scipy.signal import convolve2d\n\n\ndef get_rects(imgr, centroids, door, get_max=True):\n    bounds = get_mask(centroids, point_s=8).astype(np.uint8)\n    d = ~get_mask(door.centroid, point_s=30).astype(np.uint8)\n#     imgr[:, :, 0] = (imgr[:, :, 0] - d).astype(np.uint8)\n#     plt.imshow(imgr)\n#     plt.gca().invert_yaxis() \n#     plt.show()\n    img = (imgr).astype(np.uint8)\n    img[np.where(bounds == 0)] = 0\n\n    if get_max:\n        kernel = np.ones((5, 5))\n        convolved = convolve2d(imgr.reshape((256, 256)), kernel, mode='valid')\n        y, x = np.unravel_index(np.argmax(convolved), convolved.shape)\n        return [Point(x, y)]\n\n    shapes = []\n    cnts = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    for i, c in enumerate(cnts[0]):\n        M = cv2.moments(c)\n        box = cv2.boundingRect(c);\n        x1, y1, w, h = box\n        x2, y2 = x1 + w, y1 + h\n\n        ii = img[y1:y2, x1:x2]\n        \n        ii = ii * (ii >= np.median(imgr))\n        intensity = np.sum(ii)\n\n        if not M[\"m00\"]:\n            continue\n        cx = M[\"m10\"] / M[\"m00\"]\n        cy = M[\"m01\"] / M[\"m00\"]\n        shapes.append([cx, cy, intensity])\n\n    return [Point(*i[:2]) for i in sorted(shapes, key=lambda x: x[2], reverse=True)]\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.197430Z","iopub.status.idle":"2023-09-13T01:20:18.198247Z","shell.execute_reply.started":"2023-09-13T01:20:18.197939Z","shell.execute_reply":"2023-09-13T01:20:18.197966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i1 = None\ndef get_centroid(inner, door, bedn, bathn, task, area, bedrooms=[], bathrooms=[], plot=True):\n    global i1\n    x1 = get_input(inner=inner, door=door, bedn=bedn, bathn=bathn, task=task, area=area,\n                   bedrooms=bedrooms, bathrooms=bathrooms).unsqueeze(0).cuda()\n    o1 = model_2(x1) * x1[:, 1, :, :]\n\n    inp1 = x1[0].permute(1, 2, 0).cpu().detach().numpy()[:,:,[19, 1, 18]]\n    inp1[:, :, 1] = inp1[:, :, 1] - inp1[:, :, 0]\n    inp1[:, :, 1] = inp1[:, :, 1] - inp1[:, :, 2]\n    inp1[:, :, [0, 2]] += x1[0].permute(1, 2, 0).cpu().detach().numpy()[:,:,[0, 0]]\n    inp3 = o1[0].permute(1, 2, 0).cpu().detach().numpy()[:,:,:]\n    \n    if task=='bed1':\n        i1 = inp3\n    im =inp3\n    img = cv2.GaussianBlur(im, (15, 15), 5)\n    blobs_log = blob_log(img, min_sigma=4, max_sigma=30, threshold=0.01)\n    bed_centroids = [Point(i[1], i[0]) for i in blobs_log]\n\n    bed_centroids = get_rects(im, bed_centroids, door)[0]\n\n            \n    if plot:\n        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n\n        # display each image on each subplot\n        axs[0].imshow(inp1, cmap='inferno' )\n        axs[0].set_title(\"Input\")\n        \n        axs[1].imshow(inp3, cmap='inferno' )\n        axs[1].set_title(\"Output\")\n\n        bed_centroids_in = get_mask(bed_centroids, point_s=5)\n        axs[2].imshow(bed_centroids_in, cmap='inferno' )\n        axs[2].set_title(\"Segmented output\")\n\n        for a in axs:\n            a.invert_yaxis()\n            \n        fig.suptitle(task, fontsize=16)  # set title for the whole figure\n        plt.show()\n        \n    return bed_centroids\n\nbedrooms_predicted_centroids = []\nbathrooms_predicted_centroids = []\nkitchen_predicted_centroids = []\nbed_n = 2\nbath_n = 2\narea=140\nfor i in range(bed_n):\n    task = f\"bed{i+1}\"\n    c = get_centroid(inner, door, bedn=bed_n, bathn=bath_n, task=task, area=area, bedrooms=bedrooms_predicted_centroids, bathrooms=bathrooms_predicted_centroids)\n    bedrooms_predicted_centroids.append(c)\n\nfor i in range(bath_n):\n    task = f\"bath{i+1}\"\n    c = get_centroid(inner, door, bedn=bed_n, bathn=bath_n, task=task, area=area, bedrooms=bedrooms_predicted_centroids, bathrooms=bathrooms_predicted_centroids)\n    bathrooms_predicted_centroids.append(c)\n    \ntask = f\"kit\"\nc = get_centroid(inner, door, bedn=bed_n, bathn=bath_n, task=task, area=area, bedrooms=bedrooms_predicted_centroids, bathrooms=bathrooms_predicted_centroids)\nkitchen_predicted_centroids.append(c)    \n# task = f\"kit\"\n# c = get_centroid(inner, door, bedn=bed_n, bathn=bath_n, task=task, area=area, bedrooms=bedrooms_predicted_centroids, bathrooms=kitchen_predicted_centroids + bathrooms_predicted_centroids)\n# kitchen_predicted_centroids.append(c)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.199753Z","iopub.status.idle":"2023-09-13T01:20:18.200576Z","shell.execute_reply.started":"2023-09-13T01:20:18.200299Z","shell.execute_reply":"2023-09-13T01:20:18.200328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colors = ['Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', 'BuPu_r', 'CMRmap', 'CMRmap_r', 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens', 'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r', 'PRGn', 'PRGn_r', 'Paired', 'Paired_r', 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', 'PuOr_r', 'PuRd', 'PuRd_r', 'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', 'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', 'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', 'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r', 'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r', 'autumn', 'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r', 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r', 'cool', 'cool_r', 'coolwarm', 'coolwarm_r', 'copper', 'copper_r', 'cubehelix', 'cubehelix_r', 'flag', 'flag_r', 'gist_earth', 'gist_earth_r', 'gist_gray', 'gist_gray_r', 'gist_heat', 'gist_heat_r', 'gist_ncar', 'gist_ncar_r', 'gist_rainbow', 'gist_rainbow_r', 'gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r', 'gnuplot_r', 'gray', 'gray_r', 'hot', 'hot_r', 'hsv', 'hsv_r', 'inferno', 'inferno_r', 'jet', 'jet_r', 'magma', 'magma_r', 'nipy_spectral', 'nipy_spectral_r', 'ocean', 'ocean_r', 'pink', 'pink_r', 'plasma', 'plasma_r', 'prism', 'prism_r', 'rainbow', 'rainbow_r', 'seismic', 'seismic_r', 'spring', 'spring_r', 'summer', 'summer_r', 'tab10', 'tab10_r', 'tab20', 'tab20_r', 'tab20b', 'tab20b_r', 'tab20c', 'tab20c_r', 'terrain', 'terrain_r', 'turbo', 'turbo_r', 'twilight', 'twilight_r', 'twilight_shifted', 'twilight_shifted_r', 'viridis', 'viridis_r', 'winter', 'winter_r']\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.202030Z","iopub.status.idle":"2023-09-13T01:20:18.202972Z","shell.execute_reply.started":"2023-09-13T01:20:18.202664Z","shell.execute_reply":"2023-09-13T01:20:18.202695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"\n\ngpd.GeoSeries([inner, door] + [GeometryCollection(i) for i in [bedrooms_predicted_centroids, bathrooms_predicted_centroids, kitchen_predicted_centroids] ]).plot(cmap=\"plasma\", markersize=100 )\n\nplt.show()\n\n\nprint(bedrooms_predicted_centroids)\nprint(bathrooms_predicted_centroids)\nprint(kitchen_predicted_centroids)\nprint(door)\nprint(inner)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.204513Z","iopub.status.idle":"2023-09-13T01:20:18.205349Z","shell.execute_reply.started":"2023-09-13T01:20:18.205025Z","shell.execute_reply":"2023-09-13T01:20:18.205052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    for j, (inputs, labels) in  enumerate(plan_dataloader_val):\n        inputs, labels = inputs.cuda(),  labels.cuda()\n        outputs = model(inputs)\n        loss = loss_fn(outputs, labels)\n        val_loss.append(loss.detach().cpu().item())\n        val_acc.append(np.mean(accuracy_2(labels.cpu(), outputs.cpu())))\n\n        if j == 0:\n            inp1 = inputs[0].permute(1, 2, 0).cpu().detach().numpy()[:,:,[0, 1, 1]]\n            inp2 = labels[0].permute(1, 2, 0).cpu().detach().numpy()[:,:,:]\n            inp3 = outputs[0].permute(1, 2, 0).cpu().detach().numpy()[:,:,:]\n        break\n\n\nprint('Epoch {} - Train Loss: {:.6f} | Val Loss: {:.6f} | Train accuracy: {:.6f} | Val accuracy {:.6f} '.format(epoch+1, np.mean(train_loss), np.mean(val_loss), np.mean(train_acc), np.mean(val_acc)))\nval_loss = []\ntrain_loss = []\ntrain_acc = []\nval_acc = []\n\n\nplt.imshow( inp1, origin='lower' )\nplt.show()\nplt.imshow( inp2, origin='lower' )\nplt.show()\nplt.imshow( inp3, origin='lower' )\nplt.show()\nim = imfy(inp3)\nimg = cv2.GaussianBlur(im, (15, 15), 5)\nblobs_log = blob_log(img, min_sigma=6, max_sigma=30, threshold=0.01)\nbed_centroids = [Point(i[1], i[0]) for i in blobs_log]\ntry:\n    bed_centroids = get_rects(im, bed_centroids)[0]\nexcept:\n    bed_centroids = []\nbed_centroids_in = get_mask(bed_centroids, point_s=8)\nplt.imshow( bed_centroids_in, origin='lower' )\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.206810Z","iopub.status.idle":"2023-09-13T01:20:18.207635Z","shell.execute_reply.started":"2023-09-13T01:20:18.207356Z","shell.execute_reply":"2023-09-13T01:20:18.207383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef imfy(img):\n    return (np.clip(img, 0, 1) * 255).astype(np.uint8)\n\n\ndef get_rects(imgr, centroids):\n    bounds = get_mask(centroids, point_s=8).astype(np.uint8)\n    img = (imgr).astype(np.uint8)\n    #     img[bounds>0] = 0\n\n    img[np.where(bounds == 0)] = 0\n    # plt.imshow(img)\n    # plt.show()\n\n    shapes = []\n    cnts = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    for i, c in enumerate(cnts[0]):\n        M = cv2.moments(c)\n        box = cv2.boundingRect(c);\n        x1, y1, w, h = box\n        x2, y2 = x1 + w, y1 + h\n\n        ii = imgr[y1:y2, x1:x2]\n\n        intensity = np.mean(ii)\n\n        if not M[\"m00\"]:\n            continue\n        cx = M[\"m10\"] / M[\"m00\"]\n        cy = M[\"m01\"] / M[\"m00\"]\n        shapes.append([cx, cy, intensity])\n\n    return [Point(*i[:2]) for i in sorted(shapes, key=lambda x: x[2], reverse=True)]\n\n\ndef get_rects_2(channel, gcenters=True):\n    a = channel.copy()\n\n    a[a < 0.9] = 0\n    a[a > 1] = 1\n\n    a = (255 * a).astype(np.uint8)\n\n    _, thresh = cv2.threshold(a, 0, 255, cv2.THRESH_OTSU)\n\n    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n    final_c = []\n    centers = []\n    for c in contours:\n        perimeter = cv2.arcLength(c, True)\n        approx = cv2.approxPolyDP(c, 0.01 * perimeter, True)\n        x, y, w, h = cv2.boundingRect(approx)\n        shapely_box = box(x, y, x + w, y + h)\n        final_c.append(shapely_box.buffer(5, join_style=2, cap_style=2))\n\n        mask = np.zeros((256, 256))\n        mask = cv2.drawContours(mask, [c], -1, 255, -1)\n\n        rms = channel.copy()\n        rms[mask == 0] = 0\n\n        M = cv2.moments(rms)\n        cX = int(M[\"m10\"] / M[\"m00\"])\n        cY = int(M[\"m01\"] / M[\"m00\"])\n        centers.append(Point(cX, cY))\n\n    if gcenters:\n        return centers\n    return MultiPolygon(final_c).buffer(0)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.209112Z","iopub.status.idle":"2023-09-13T01:20:18.209940Z","shell.execute_reply.started":"2023-09-13T01:20:18.209658Z","shell.execute_reply":"2023-09-13T01:20:18.209686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://kkb-production.jupyter-proxy.kaggle.net/k/135566844/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2IiwidHlwIjoiSldUIn0..WLiAt3FH-rYm5_WhdDdgiw.stF9Kn3XBkHPDCo3PIYGXlPMmEinxV8-_6Dmtc2HVl-q_NUpyY73NAqDex76zk8O1GOPXf9bZn3ES8D1sMIvX73DMwZkrkblZZ0FimPkNQ5C_L3iA5oOPS4uC3NufmJorIfNCBDfqC6S7RmxWKe2hJueQzyDraega-fdiqjIRcTbeuGk-kNbQMP67XzZKFiLga2Mhoeq0StrgDtsQSG74g.JGjOLtbpCgQnxFP9Zqy_ag/proxy/files/bedroom_0.pth","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.211411Z","iopub.status.idle":"2023-09-13T01:20:18.212236Z","shell.execute_reply.started":"2023-09-13T01:20:18.211930Z","shell.execute_reply":"2023-09-13T01:20:18.211958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model, '/kaggle/working/bedroom_first_unet_1000.pth')","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.213689Z","iopub.status.idle":"2023-09-13T01:20:18.214516Z","shell.execute_reply.started":"2023-09-13T01:20:18.214242Z","shell.execute_reply":"2023-09-13T01:20:18.214269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# pix2Pix\n","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport cv2\nfrom tqdm.auto import tqdm\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.215959Z","iopub.status.idle":"2023-09-13T01:20:18.216772Z","shell.execute_reply.started":"2023-09-13T01:20:18.216493Z","shell.execute_reply":"2023-09-13T01:20:18.216520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/eriklindernoren/PyTorch-GAN/\n%cd PyTorch-GAN/implementations/pix2pix","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.218253Z","iopub.status.idle":"2023-09-13T01:20:18.219056Z","shell.execute_reply.started":"2023-09-13T01:20:18.218780Z","shell.execute_reply":"2023-09-13T01:20:18.218807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport math\nimport itertools\nimport time\nimport datetime\nimport sys\n\nimport torchvision.transforms as transforms\nfrom torchvision.utils import save_image\n\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torch.autograd import Variable\n\nfrom models import *\nfrom datasets import *\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.220530Z","iopub.status.idle":"2023-09-13T01:20:18.221352Z","shell.execute_reply.started":"2023-09-13T01:20:18.221043Z","shell.execute_reply":"2023-09-13T01:20:18.221070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class opt:\n    epoch = 0\n    n_epochs = 10 #change to 50 for train\n    dataset_name = 'test1'\n    batch_size = 3\n    lr = 0.0002\n    b1 = 0.5\n    b2 = 0.999\n    decay_epoch = 100\n    n_cpu = 4\n    img_height = 256\n    img_width = 256\n    channels = 4\n    sample_interval = 100\n    checkpoint_interval = 1","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.222810Z","iopub.status.idle":"2023-09-13T01:20:18.223629Z","shell.execute_reply.started":"2023-09-13T01:20:18.223348Z","shell.execute_reply":"2023-09-13T01:20:18.223375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs(\"/kaggle/working/images/%s\" % opt.dataset_name, exist_ok=True)\nos.makedirs(\"/kaggle/working/saved_models/%s\" % opt.dataset_name, exist_ok=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.225070Z","iopub.status.idle":"2023-09-13T01:20:18.225910Z","shell.execute_reply.started":"2023-09-13T01:20:18.225626Z","shell.execute_reply":"2023-09-13T01:20:18.225654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cuda = True if torch.cuda.is_available() else False\n\n# Loss functions\ncriterion_GAN = torch.nn.MSELoss()\ncriterion_pixelwise = torch.nn.L1Loss()\n\n# Loss weight of L1 pixel-wise loss between translated image and real image\nlambda_pixel = 100\n\n# Calculate output of image discriminator (PatchGAN)\npatch = (1, opt.img_height // 2 ** 4, opt.img_width // 2 ** 4)\n\n# Initialize generator and discriminator\ngenerator = GeneratorUNet()\ndiscriminator = Discriminator()\n# with open('gen_draw_rooms.pth', 'rb') as f:\n#     generator = torch.load(f).cuda()\n\nif cuda:\n    generator = generator.cuda()\n    discriminator = discriminator.cuda()\n    criterion_GAN.cuda()\n    criterion_pixelwise.cuda()\n\nif opt.epoch != 0:\n    # Load pretrained models\n    generator.load_state_dict(torch.load(\"/kaggle/working/saved_models/%s/generator_%d.pth\" % (opt.dataset_name, opt.epoch)))\n    discriminator.load_state_dict(torch.load(\"/kaggle/working/saved_models/%s/discriminator_%d.pth\" % (opt.dataset_name, opt.epoch)))\nelse:\n    # Initialize weights\n    generator.apply(weights_init_normal)\n    discriminator.apply(weights_init_normal)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.227408Z","iopub.status.idle":"2023-09-13T01:20:18.228240Z","shell.execute_reply.started":"2023-09-13T01:20:18.227931Z","shell.execute_reply":"2023-09-13T01:20:18.227959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"1e-3","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.229691Z","iopub.status.idle":"2023-09-13T01:20:18.230511Z","shell.execute_reply.started":"2023-09-13T01:20:18.230231Z","shell.execute_reply":"2023-09-13T01:20:18.230261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer_G = torch.optim.Adam(generator.parameters(), lr= 0.0001, betas=(opt.b1, opt.b2))\noptimizer_D = torch.optim.Adam(discriminator.parameters(), lr= 0.0001, betas=(opt.b1, opt.b2))","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.231949Z","iopub.status.idle":"2023-09-13T01:20:18.232783Z","shell.execute_reply.started":"2023-09-13T01:20:18.232500Z","shell.execute_reply":"2023-09-13T01:20:18.232529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.234241Z","iopub.status.idle":"2023-09-13T01:20:18.235041Z","shell.execute_reply.started":"2023-09-13T01:20:18.234768Z","shell.execute_reply":"2023-09-13T01:20:18.234795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sample_images(batches_done):\n    \"\"\"Saves a generated sample from the validation set\"\"\"\n    X, y = next(iter(plan_dataloader_val))\n    with torch.no_grad():\n        outputs = model(X.cuda()).cpu()\n        X = outputs\n    real_A = Variable(X.type(Tensor))\n    real_B = Variable(y.type(Tensor))\n    fake_B = generator(real_A)\n    img_sample = torch.cat((real_A.data, fake_B.data, real_B.data), -2).cpu().numpy().astype(np.float32)\n    img_sample -=img_sample.min()\n    img_sample/=img_sample.max()\n    img_sample = img_sample.transpose(0,2,3,1)\n    plt.figure(figsize=[10,20])\n    for row in range(3):\n        plt.subplot(1,3,row+1)\n        plt.imshow(img_sample[row])\n    plt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.236514Z","iopub.status.idle":"2023-09-13T01:20:18.237335Z","shell.execute_reply.started":"2023-09-13T01:20:18.237025Z","shell.execute_reply":"2023-09-13T01:20:18.237052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator.model[0] = nn.Conv2d(2, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)).cuda()\ngenerator.down1.model[0] = nn.Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)).cuda()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.238769Z","iopub.status.idle":"2023-09-13T01:20:18.239589Z","shell.execute_reply.started":"2023-09-13T01:20:18.239308Z","shell.execute_reply":"2023-09-13T01:20:18.239335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator.final[2] = nn.Conv2d(128, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1)).cuda()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.241029Z","iopub.status.idle":"2023-09-13T01:20:18.241847Z","shell.execute_reply.started":"2023-09-13T01:20:18.241567Z","shell.execute_reply":"2023-09-13T01:20:18.241594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_plans, test_plans = train_test_split(plans, test_size=0.02, shuffle=True, random_state=1997)\n\n\n\ntrain_plans = [i for i in train_plans if i['front'] and i['kitchen'] and i['general']]\ntest_plans = [i for i in test_plans if i['front'] and i['kitchen'] and i['general']]\n\nplan_dataset = PlanDataset(train_plans)\nplan_dataset_val = PlanDataset(test_plans)\n\nplan_dataloader = DataLoader(plan_dataset, batch_size=16, shuffle=True, num_workers=opt.n_cpu)\nplan_dataloader_val = DataLoader(plan_dataset_val, batch_size=16, shuffle=True, num_workers=opt.n_cpu)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.243318Z","iopub.status.idle":"2023-09-13T01:20:18.244114Z","shell.execute_reply.started":"2023-09-13T01:20:18.243831Z","shell.execute_reply":"2023-09-13T01:20:18.243859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### prev_time = time.time()\n\nfor epoch in range(opt.epoch, 100):\n    for i, (X, y) in enumerate(plan_dataloader):\n\n\n\n        # ------------------\n        #  Train Generators\n        # ------------------\n\n        optimizer_G.zero_grad()\n        \n        X = X.cuda()\n        \n        with torch.no_grad():\n            outputs = model(X)\n            X = outputs\n                    \n                    \n        y = y.cuda()\n        \n        # Adversarial ground truths\n        valid = Variable(Tensor(np.ones((X.size(0), *patch))), requires_grad=False)\n        fake = Variable(Tensor(np.zeros((X.size(0), *patch))), requires_grad=False)\n        \n        # GAN loss\n        fake_B = generator(X)\n        pred_fake = discriminator(fake_B, X)\n        loss_GAN = criterion_GAN(pred_fake, valid)\n        # Pixel-wise loss\n        loss_pixel = criterion_pixelwise(fake_B, y)\n\n        # Total loss\n        loss_G = loss_GAN + lambda_pixel * loss_pixel\n\n        loss_G.backward()\n\n        optimizer_G.step()\n\n        # ---------------------\n        #  Train Discriminator\n        # ---------------------\n\n        optimizer_D.zero_grad()\n\n        # Real loss\n        pred_real = discriminator(y, X)\n        loss_real = criterion_GAN(pred_real, valid)\n\n        # Fake loss\n        pred_fake = discriminator(fake_B.detach(), X)\n        loss_fake = criterion_GAN(pred_fake, fake)\n\n        # Total loss\n        loss_D = 0.5 * (loss_real + loss_fake)\n\n        loss_D.backward()\n        optimizer_D.step()\n\n        # --------------\n        #  Log Progress\n        # --------------\n\n        # Determine approximate time left\n        batches_done = epoch * len(plan_dataloader) + i\n        batches_left = opt.n_epochs * len(plan_dataloader) - batches_done\n        time_left = 0\n        prev_time = 0\n\n        # Print log\n        sys.stdout.write(\n            \"\\r[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f, pixel: %f, adv: %f] ETA: %s\"\n            % (\n                epoch,\n                opt.n_epochs,\n                i,\n                len(plan_dataloader),\n                loss_D.item(),\n                loss_G.item(),\n                loss_pixel.item(),\n                loss_GAN.item(),\n                time_left,\n            )\n        )\n\n        # If at sample interval save image\n        if batches_done % 1000 == 0:\n            sample_images(batches_done)\n\n    if opt.checkpoint_interval != -1 and epoch % opt.checkpoint_interval== 0:\n        # Save model checkpoints\n        torch.save(generator.state_dict(), \"/kaggle/working/saved_models/%s/generator_%d.pth\" % (opt.dataset_name, epoch))\n        torch.save(discriminator.state_dict(), \"/kaggle/working/saved_models/%s/discriminator_%d.pth\" % (opt.dataset_name, epoch))","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.245854Z","iopub.status.idle":"2023-09-13T01:20:18.246678Z","shell.execute_reply.started":"2023-09-13T01:20:18.246399Z","shell.execute_reply":"2023-09-13T01:20:18.246427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.load(generator, 'gen_draw_rooms.pth')","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.248105Z","iopub.status.idle":"2023-09-13T01:20:18.248923Z","shell.execute_reply.started":"2023-09-13T01:20:18.248645Z","shell.execute_reply":"2023-09-13T01:20:18.248672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import requests\n\nfiles = {\n    'file': ('gen_draw_rooms.pth', open('gen_draw_rooms.pth', 'rb')),\n}\n\nurl = 'https://api.anonfiles.com/upload'\nresponse = requests.post(url, files=files)\n\ndata = response.json()\n\nprint(data['data']['file']['url']['short'])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.250397Z","iopub.status.idle":"2023-09-13T01:20:18.251206Z","shell.execute_reply.started":"2023-09-13T01:20:18.250907Z","shell.execute_reply":"2023-09-13T01:20:18.250934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Test","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bed_model = BedCentRegressor().load_from_checkpoint(\"/kaggle/input/bed-centroids-70ep/xxyy/epoch=20-step=15435.ckpt\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.252651Z","iopub.status.idle":"2023-09-13T01:20:18.253458Z","shell.execute_reply.started":"2023-09-13T01:20:18.253174Z","shell.execute_reply":"2023-09-13T01:20:18.253202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bath_model = BedCentRegressor().load_from_checkpoint(\"/kaggle/input/bathroom-more-train/xxyy/epoch=13-step=10290.ckpt\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.254893Z","iopub.status.idle":"2023-09-13T01:20:18.255713Z","shell.execute_reply.started":"2023-09-13T01:20:18.255431Z","shell.execute_reply":"2023-09-13T01:20:18.255458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kit_model = BedCentRegressor().load_from_checkpoint(\"/kaggle/input/kitchen-model/kitchen.ckpt\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.257170Z","iopub.status.idle":"2023-09-13T01:20:18.257974Z","shell.execute_reply.started":"2023-09-13T01:20:18.257694Z","shell.execute_reply":"2023-09-13T01:20:18.257722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d = \"\"\"\nPOLYGON ((139.8806629834254 195.8895027624309, 139.8806629834254 200.4154696132597, 157.9845303867403 200.4154696132597, 157.9845303867403 195.8895027624309, 139.8806629834254 195.8895027624309))\nPOLYGON ((26.73149171270718 76.33964778841968, 25.59999999999999 77.47113950112686, 25.59999999999999 107.2448825983206, 26.73149171270718 108.3763743110278, 26.73149171270718 130.2629834254143, 49.36132596685083 130.2629834254143, 49.36132596685083 199.2839779005525, 230.4 199.2839779005525, 230.4 56.71602209944751, 26.73149171270718 56.71602209944751, 26.73149171270718 76.33964778841968))\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.259452Z","iopub.status.idle":"2023-09-13T01:20:18.260287Z","shell.execute_reply.started":"2023-09-13T01:20:18.259974Z","shell.execute_reply":"2023-09-13T01:20:18.260001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\n\npattern = r'<POINT \\((\\d+(?:\\.\\d+)?)\\s(\\d+(?:\\.\\d+)?)\\)>'\n\ndef parse_points(input_str):\n    coords_str = re.findall(pattern, input_str)\n    points = [Point(float(x), float(y)) for x, y in coords_str]\n    return points\n\n\nd = d.split(\"\\n\")\n# points = [parse_points(i) for i in d if \"POINT\" in i]\npolygon = [shapely.from_wkt(i) for i in d if \"POLYGON\" in i]\n\ninner_poly = max(polygon, key=lambda x: x.area)\ndoor_poly = min(polygon, key=lambda x: x.area)\n# bedrooms, bathrooms =  points","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.261745Z","iopub.status.idle":"2023-09-13T01:20:18.262572Z","shell.execute_reply.started":"2023-09-13T01:20:18.262292Z","shell.execute_reply":"2023-09-13T01:20:18.262321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval();","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.264001Z","iopub.status.idle":"2023-09-13T01:20:18.264824Z","shell.execute_reply.started":"2023-09-13T01:20:18.264545Z","shell.execute_reply":"2023-09-13T01:20:18.264573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport numpy as np\nfrom scipy.signal import convolve2d\nfrom skimage.feature import blob_dog, blob_log, blob_doh\n\n\ndef get_rects(imgr, centroids, door, get_max=0):\n    bounds = get_mask(centroids, point_s=8).astype(np.uint8)\n    d = ~get_mask(door.centroid, point_s=30).astype(np.uint8)\n#     imgr[:, :, 0] = (imgr[:, :, 0] - d).astype(np.uint8)\n#     plt.imshow(imgr)\n#     plt.gca().invert_yaxis() \n#     plt.show()\n    img = (imgr).astype(np.uint8)\n    img[np.where(bounds == 0)] = 0\n\n    if get_max:\n        kernel = np.ones((8, 8))\n        convolved = convolve2d(imgr.reshape((256, 256)), kernel, mode='valid')\n        plt.imshow(convolved)\n        plt.show()\n        y, x = np.unravel_index(np.argmax(convolved), convolved.shape)\n        return [Point(x, y)]\n\n    shapes = []\n    cnts = cv2.findContours(imgr, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    \n\n    for i, c in enumerate(cnts[0]):\n        M = cv2.moments(c)\n        box = cv2.boundingRect(c);\n        x1, y1, w, h = box\n        x2, y2 = x1 + w, y1 + h\n\n        ii = img[y1:y2, x1:x2]\n        \n        ii = ii * (ii >= np.median(imgr))\n        intensity = np.sum(ii)\n\n        if not M[\"m00\"]:\n            continue\n        cx = M[\"m10\"] / M[\"m00\"]\n        cy = M[\"m01\"] / M[\"m00\"]\n        shapes.append([cx, cy, intensity])\n\n    return [Point(*i[:2]) for i in sorted(shapes, key=lambda x: x[2], reverse=True)]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.266332Z","iopub.status.idle":"2023-09-13T01:20:18.267124Z","shell.execute_reply.started":"2023-09-13T01:20:18.266845Z","shell.execute_reply":"2023-09-13T01:20:18.266872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# bed_model.eval();\n# bath_model.eval();\n# kit_model.eval();\n# bed_model.train();\n# bath_model.train();\n# kit_model.train();\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.268588Z","iopub.status.idle":"2023-09-13T01:20:18.269413Z","shell.execute_reply.started":"2023-09-13T01:20:18.269103Z","shell.execute_reply":"2023-09-13T01:20:18.269134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from shapely.geometry import LineString\nneigh = LineString([(49.36132596685083, 199.2839779005525),\n (230.4, 199.2839779005525)]).union(LineString([ (230.4, 56.71602209944751),\n (26.73149171270718, 56.71602209944751)])).buffer(1, join_style=2)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.270841Z","iopub.status.idle":"2023-09-13T01:20:18.271652Z","shell.execute_reply.started":"2023-09-13T01:20:18.271375Z","shell.execute_reply":"2023-09-13T01:20:18.271403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gpd.GeoSeries([inner_poly, door_poly, neigh]).plot(cmap=\"Dark2_r\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.273100Z","iopub.status.idle":"2023-09-13T01:20:18.273931Z","shell.execute_reply.started":"2023-09-13T01:20:18.273650Z","shell.execute_reply":"2023-09-13T01:20:18.273678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# bedrooms = []\n# bathrooms = []\n\n\n\n# no_bedrooms = 3\n# no_bathrooms = 3\n\n# area = 180.0\n# area = min(area / 400, 1)\n\n# for i in range(no_bedrooms):\n#     x = np.zeros((2, 256, 256 , 9))\n\n#     x[0,:,:,0] = get_mask(door_poly.centroid, (256, 256), point_s=5) > 0\n#     x[0,:,:,1] = get_mask(inner_poly, (256, 256), point_s=5) > 0\n\n#     length_box = 256*area/2\n#     x[0,:,:,2] = get_mask(box(128-length_box, 128-length_box, 128+length_box, 128+length_box), (256, 256), point_s=10) > 0        \n#     x[0,:,:,3] = get_mask([neigh], (256, 256), point_s=5) > 0\n#     x[0,:,:,4] = get_mask(bedrooms, (256, 256), point_s=5) > 0\n#     x[0,:,:,4 + no_bedrooms] = 1.0\n\n#     out = bed_model(torch.from_numpy(x).permute((0, 3, 1, 2)).cuda().float())\n#     out = out.detach().cpu()[0][0]\n\n#     im = out.numpy()\n#     current = get_mask(bedrooms, point_s=10)\n#     im[current!=0] = 0\n#     img = cv2.GaussianBlur(im, (15, 15), 5)\n# #     plt.imshow(img)\n# #     plt.show()\n#     blobs_log = blob_log(img, min_sigma=4, max_sigma=30, threshold=0.01)\n#     bed_centroids = [Point(i[1], i[0]) for i in blobs_log]\n#     centroids = get_rects(im, bed_centroids, door_poly, get_max=True)\n#     bedrooms.extend(centroids)\n\n    \n# for i in range(no_bathrooms):\n#     x = np.zeros((2, 256, 256 , 9))\n\n#     x[0,:,:,0] = get_mask(door_poly.centroid, (256, 256), point_s=5) > 0\n#     x[0,:,:,1] = get_mask(inner_poly, (256, 256), point_s=5) > 0\n\n#     length_box = 256*area/2\n#     x[0,:,:,2] = get_mask(box(128-length_box, 128-length_box, 128+length_box, 128+length_box), (256, 256), point_s=10) > 0        \n#     x[0,:,:,3] = get_mask([neigh], (256, 256), point_s=5) > 0\n#     x[0,:,:,4] = get_mask(bedrooms, (256, 256), point_s=5) > 0\n#     x[0,:,:,5] = get_mask(bathrooms, (256, 256), point_s=5) > 0\n#     x[0,:,:,4 + no_bathrooms] = 1.0\n\n#     out = bath_model(torch.from_numpy(x).permute((0, 3, 1, 2)).cuda().float())\n#     out = out.detach().cpu()[0][0]\n\n# #     plt.imshow(out)\n# #     plt.show()\n\n#     im = out.numpy()\n#     current = get_mask(bedrooms + bathrooms, point_s=10)\n#     im[current!=0] = 0\n#     img = cv2.GaussianBlur(im, (15, 15), 5)\n# #     plt.imshow(img)\n# #     plt.show()\n#     blobs_log = blob_log(img, min_sigma=4, max_sigma=30, threshold=0.01)\n#     bath_centroids = [Point(i[1], i[0]) for i in blobs_log]\n#     centroids = get_rects(im, bath_centroids, door_poly, get_max=True)\n#     bathrooms.extend(centroids)\n    \n\n# x = np.zeros((2, 256, 256 , 9))\n\n# x[0,:,:,0] = get_mask(door_poly.centroid, (256, 256), point_s=5) > 0\n# x[0,:,:,1] = get_mask(inner_poly, (256, 256), point_s=5) > 0\n\n# length_box = 256*area/2\n# x[0,:,:,2] = get_mask(box(128-length_box, 128-length_box, 128+length_box, 128+length_box), (256, 256), point_s=10) > 0        \n# x[0,:,:,3] = get_mask([neigh], (256, 256), point_s=5) > 0\n# x[0,:,:,4] = get_mask(bedrooms, (256, 256), point_s=5) > 0\n# x[0,:,:,5] = get_mask(bathrooms, (256, 256), point_s=5) > 0\n\n# out = kit_model(torch.from_numpy(x).permute((0, 3, 1, 2)).cuda().float())\n# out = out.detach().cpu()[0][0]\n\n# # plt.imshow(out)\n# # plt.show()\n\n# im = out.numpy()\n# current = get_mask(bedrooms + bathrooms, point_s=10)\n# im[current!=0] = 0\n# img = cv2.GaussianBlur(im, (15, 15), 5)\n# plt.imshow(img)\n# plt.show()\n# blobs_log = blob_log(img, min_sigma=4, max_sigma=30, threshold=0.01)\n# kit_centroids = [Point(i[1], i[0]) for i in blobs_log]\n# centroids = get_rects(im, kit_centroids, door_poly, get_max=True)\n# kitchen = centroids[0]\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.275477Z","iopub.status.idle":"2023-09-13T01:20:18.276295Z","shell.execute_reply.started":"2023-09-13T01:20:18.275986Z","shell.execute_reply":"2023-09-13T01:20:18.276014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# aio_model = BedCentRegressor().load_from_checkpoint(\"/kaggle/working/xxyy/epoch=20-step=14028.ckpt\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.277759Z","iopub.status.idle":"2023-09-13T01:20:18.278576Z","shell.execute_reply.started":"2023-09-13T01:20:18.278297Z","shell.execute_reply":"2023-09-13T01:20:18.278325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = model.cuda()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.280015Z","iopub.status.idle":"2023-09-13T01:20:18.280842Z","shell.execute_reply.started":"2023-09-13T01:20:18.280565Z","shell.execute_reply":"2023-09-13T01:20:18.280593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef get_rects(imgr, centroids, door, get_max=0):\n    bounds = get_mask(centroids, point_s=8).astype(np.uint8)\n    d = ~get_mask(door.centroid, point_s=30).astype(np.uint8)\n    img = (imgr).astype(np.uint8)\n    img[np.where(bounds == 0)] = 0\n\n    if get_max:\n        kernel = np.ones((1, 1))\n        convolved = convolve2d(imgr.reshape((256, 256)), kernel, mode='same', boundary='fill', fillvalue=0)\n#         plt.imshow(imgr)\n#         plt.show()\n        y, x = np.unravel_index(np.argmax(convolved), convolved.shape)\n        return [Point(x, y)]\n    \n    \ndef get_rects(imgr, centroids, door, get_max=0):\n    bounds = get_mask(centroids, point_s=8)\n#     d = ~get_mask(door.centroid, point_s=6).astype(np.uint8)\n#     imgr[:, :, 0] = (imgr[:, :, 0] - d).astype(np.uint8)\n#     plt.imshow(imgr)\n#     plt.gca().invert_yaxis() \n#     plt.show()\n#     imgr = abs((imgr*bounds*255)).astype(np.uint8)\n    \n    imgr[np.where(bounds == 0)] = 0\n    \n    kernel = np.ones((2, 2))\n    convolved = convolve2d(imgr.reshape((256, 256)), kernel, mode='valid')\n#     convolved = convolved - np.min(convolved)\n#     convolved = (convolved * 255 / np.max(convolved)).astype(np.uint8)\n     \n    blobs_log = blob_log(convolved, min_sigma=3, max_sigma=30, threshold=0.01)\n#     plt.imshow(convolved)\n#     plt.show()\n    try:\n        p = max(blobs_log, key=lambda c: convolved[int(c[1]), int(c[0])])[:2]\n        return [Point(*p[::-1])]\n    \n    except:\n        \n        return []\n    \n    \n    \n    \n    \n    if get_max:\n        y, x = np.unravel_index(np.argmax(convolved), convolved.shape)\n        return [Point(x, y)]\n    shapes = []\n    cnts = cv2.findContours(convolved, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    for i, c in enumerate(cnts[0]):\n        M = cv2.moments(c)\n        box = cv2.boundingRect(c);\n        x1, y1, w, h = box\n        x2, y2 = x1 + w, y1 + h\n\n        ii = convolved[y1:y2, x1:x2]\n\n#         ii = ii * (ii >= np.median(convolved))\n        \n        intensity = np.median(ii)\n\n        if not M[\"m00\"]:\n            continue\n        cx = M[\"m10\"] / M[\"m00\"]\n        cy = M[\"m01\"] / M[\"m00\"]\n        \n        shapes.append([cx, cy, intensity])\n    \n    shapes = [i[:2] for i in sorted(shapes, key=lambda x: x[2], reverse=True)]\n    if not shapes:\n        return []\n    \n    return [Point(*shapes[0])]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.282367Z","iopub.status.idle":"2023-09-13T01:20:18.283179Z","shell.execute_reply.started":"2023-09-13T01:20:18.282882Z","shell.execute_reply":"2023-09-13T01:20:18.282910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.cpu().eval();","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.284646Z","iopub.status.idle":"2023-09-13T01:20:18.285469Z","shell.execute_reply.started":"2023-09-13T01:20:18.285169Z","shell.execute_reply":"2023-09-13T01:20:18.285197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bedrooms = []\nbathrooms = []\nkitchen = []\n\n\nno_bedrooms = 3\nno_bathrooms = 2\narea = 130.0\n\narea = min(area / 400, 1)\n\nx = np.zeros((1, 256, 256 , 12))\n\n\nx[0,:,:,0] = get_mask(door_poly.centroid, (256, 256), point_s=5) > 0\nx[0,:,:,1] = get_mask(inner_poly, (256, 256), point_s=5) > 0\n\nlength_box = 256*area/2\nx[0,:,:,2] = get_mask(box(128-length_box, 128-length_box, 128+length_box, 128+length_box), (256, 256), point_s=10) > 0        \nx[0,:,:,3] = get_mask([neigh], (256, 256), point_s=5) > 0\nx[0,:,:,3 + no_bedrooms] = 1.0\nx[0,:,:,7 + no_bathrooms] = 1.0\n\n\n\nwith torch.no_grad():\n    x = torch.from_numpy(x).permute((0, 3, 1, 2)).float()\n\n    bottle_neck = model.forward_encoder_main(x)\n\n\n    for i in range(no_bedrooms + no_bathrooms + 1) :\n\n        x_task = np.zeros((1, 256, 256 , 3))\n\n        x_task[0,:,:,0] = get_mask(bedrooms, (256, 256), point_s=5) > 0\n        x_task[0,:,:,1] = get_mask(bathrooms, (256, 256), point_s=5) > 0\n        x_task[0,:,:,2] = get_mask(kitchen, (256, 256), point_s=5) > 0\n\n        if len(bedrooms) < no_bedrooms:\n    #         x_task[0,:,:,3] = 1.0\n            state = 1\n        elif len(bathrooms) < no_bathrooms:\n    #         x_task[0,:,:,4] = 1.0\n            state = 2\n        else:\n    #         x_task[0,:,:,5] = 1.0\n            state = 3\n\n        x_task = torch.from_numpy(x_task).permute((0, 3, 1, 2)).float()\n\n        other_features = model.forward_encoder_mini(x_task)\n\n\n        out = model.forward_decoder(bottle_neck, other_features, state=state)\n\n        out = out.detach().cpu()[0][0]\n\n        im = out.numpy()\n        current = get_mask(bedrooms + bathrooms, point_s=10)\n        im[current!=0] = 0\n        img = cv2.GaussianBlur(im, (15, 15), 5)\n#         plt.imshow(img)\n#         plt.show()\n        blobs_log = blob_log(img, min_sigma=4, max_sigma=30, threshold=0.01)\n        bed_centroids = [Point(i[1], i[0]) for i in blobs_log]\n        \n        centroids = get_rects(im, bed_centroids, door_poly, get_max=0)\n        print(centroids)\n        if len(bedrooms) < no_bedrooms:\n            bedrooms.extend(centroids)\n        elif len(bathrooms) < no_bathrooms:\n            bathrooms.extend(centroids)\n        else:\n            kitchen = centroids\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.286962Z","iopub.status.idle":"2023-09-13T01:20:18.287781Z","shell.execute_reply.started":"2023-09-13T01:20:18.287501Z","shell.execute_reply":"2023-09-13T01:20:18.287528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(bedrooms)\nprint(bathrooms)\nprint([kitchen])\nprint(door_poly)\nprint(inner_poly)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.289254Z","iopub.status.idle":"2023-09-13T01:20:18.290043Z","shell.execute_reply.started":"2023-09-13T01:20:18.289767Z","shell.execute_reply":"2023-09-13T01:20:18.289794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gpd.GeoSeries([inner_poly, door_poly] + [unary_union(bedrooms), unary_union(bathrooms), kitchen[0]]).plot(cmap=\"Dark2_r\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.291503Z","iopub.status.idle":"2023-09-13T01:20:18.292331Z","shell.execute_reply.started":"2023-09-13T01:20:18.292024Z","shell.execute_reply":"2023-09-13T01:20:18.292051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(x[0, :, :, 1])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.293780Z","iopub.status.idle":"2023-09-13T01:20:18.294608Z","shell.execute_reply.started":"2023-09-13T01:20:18.294324Z","shell.execute_reply":"2023-09-13T01:20:18.294352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.save_checkpoint(\"out.ckpt\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T01:20:18.296051Z","iopub.status.idle":"2023-09-13T01:20:18.296878Z","shell.execute_reply.started":"2023-09-13T01:20:18.296594Z","shell.execute_reply":"2023-09-13T01:20:18.296623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}